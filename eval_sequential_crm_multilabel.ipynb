{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d91444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import jax.numpy as np\n",
    "import numpy as np\n",
    "import numpy as onp\n",
    "import pandas as pd\n",
    "#import jaxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8087f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903694db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee82adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize as sp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d75dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94286c",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='yeast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_ = load_svmlight_file(dataset_name+'_train.svm', multilabel=True)\n",
    "X_train = onp.array(X_train.todense())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test_ = load_svmlight_file(dataset_name+'_test.svm', multilabel=True)\n",
    "X_test = onp.array(X_test.todense())\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labeller = MultiLabelBinarizer()\n",
    "y_train = onehot_labeller.fit_transform(y_train_).astype(int)\n",
    "y_test = onehot_labeller.transform(y_test_).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = onehot_labeller.classes_.astype(int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7514c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9851d08",
   "metadata": {},
   "source": [
    "FYI: Error rate of null policy (always predict 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum()/(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce192383",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ef88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_hammingloss(p,y):\n",
    "    assert p.shape == y.shape\n",
    "    pos = np.where( (p != y) & (y > 0) )\n",
    "    neg = np.where( (p != y) & (y == 0) )\n",
    "    fn = p[neg].sum()\n",
    "    fp = (1-p[pos]).sum()\n",
    "    return (fn+fp)/(p.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04304ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_hammingloss(test_probas, y_test):\n",
    "    return onp.mean([\n",
    "        micro_hammingloss(test_probas[:,k].reshape((len(y_test),1)), \n",
    "                          y_test[:,k].reshape((len(y_test),1))) \n",
    "        for k in range(y_test.shape[1])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ab902",
   "metadata": {},
   "source": [
    "---\n",
    "## Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb237dc",
   "metadata": {},
   "source": [
    "### CRM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66561e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_crm_dataset(X, y, probas, n_samples=4, labels=labels):\n",
    "    \n",
    "    assert len(X) == len(y) == len(probas), (len(X) , len(y) , len(probas))\n",
    "    \n",
    "    P = []\n",
    "    A = []\n",
    "    F = []\n",
    "    R = []\n",
    "    \n",
    "    for i in range(len(probas)):\n",
    "        for k in range(n_samples):\n",
    "            \n",
    "            p = probas[i,:]\n",
    "            p = p.astype('float32')\n",
    "            p /= p.sum()\n",
    "            \n",
    "            a = onp.random.choice(labels, p=p)\n",
    "            A += [a]\n",
    "            \n",
    "            p = p[a]\n",
    "            P += [p]\n",
    "            \n",
    "            x = X[i]\n",
    "            F += [x]\n",
    "\n",
    "            R += [int(y[i,a] > 0)]\n",
    "            \n",
    "    assert len(P) == len(X) * n_samples\n",
    "\n",
    "    return P, A, R, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03908a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayize_crm_dataset(P, A, R, F):\n",
    "    P = onp.array(P).reshape((len(P),1))\n",
    "    A = onp.array(A).reshape((len(P),1))\n",
    "    R = onp.array(R).reshape((len(P),1))\n",
    "    F = onp.vstack(F)\n",
    "    return P, A, R, F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35bab3",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ea39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_action_embeddings(features, labels):\n",
    "    \n",
    "    def onehotsingleaction(a):\n",
    "        r = onp.zeros(len(labels))\n",
    "        r[a] = 1\n",
    "        return r\n",
    "    \n",
    "    result = [\n",
    "        [onp.hstack([feature, \n",
    "                     onehotsingleaction(action)]) for action in labels] \n",
    "        for feature in features\n",
    "    ]\n",
    "    result = onp.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(parameter, queries, embeddings):\n",
    "    exponents = np.exp(np.dot(embeddings, parameter))\n",
    "    num = exponents[onp.arange(embeddings.shape[0]), queries]\n",
    "    res =  num / np.sum(exponents, axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict_on_all_actions(parameter, embeddings):\n",
    "    exponents = np.exp(np.dot(embeddings, parameter))\n",
    "    den = np.sum(exponents, axis=1).reshape(len(embeddings),1)\n",
    "    res =  exponents / den\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca06924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(beta, X, y, sampling_probas, prior_crm_dataset, samples_per_instance=4):\n",
    "    \n",
    "    P, A, R, F = prior_crm_dataset\n",
    "    \n",
    "    l = len(P)\n",
    "    \n",
    "    newP, newA, newR, newF = generate_crm_dataset(\n",
    "        X, y, sampling_probas, n_samples=samples_per_instance\n",
    "    )\n",
    "    assert len(newP) == len(X)*samples_per_instance, (len(newP), len(X), samples_per_instance)\n",
    "    \n",
    "    P += newP\n",
    "    A += newA\n",
    "    R += newR\n",
    "    F += newF\n",
    "    \n",
    "    assert len(P) == len(newP) + l, (len(P), len(newP), l)\n",
    "    \n",
    "    P_, A_, R_, F_ = arrayize_crm_dataset(P, A, R, F)    \n",
    "    phi = build_action_embeddings(F, labels)\n",
    "    \n",
    "    def fn(beta):\n",
    "        pred = model_predict(beta, A_.squeeze(), phi)\n",
    "        W = pred / P_.squeeze()\n",
    "        l = np.sum((1-R_).squeeze()*W) / np.sum(W)\n",
    "        return l\n",
    "    \n",
    "    solution = sp_minimize(fn, beta, method='L-BFGS-B')\n",
    "    newbeta = solution.x\n",
    "    \n",
    "    return newbeta, (P, A, R, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(beta, phi_test, y_test, normalize=False, binarize=True):\n",
    "    beta_test_probas = model_predict_on_all_actions(beta, phi_test)\n",
    "    if normalize:\n",
    "        beta_test_probas /= beta_test_probas.sum(axis=1).reshape((len(y_test),1))\n",
    "    if binarize:\n",
    "        beta_test_probas = (beta_test_probas > .5).astype(int)\n",
    "    return micro_hammingloss(beta_test_probas, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aef896",
   "metadata": {},
   "source": [
    "----\n",
    "## Baselines & Skylines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca56d6",
   "metadata": {},
   "source": [
    " ![Perf from CRM article](./basesky.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = GaussianRandomProjection(n_components=1000)\n",
    "\n",
    "X_train_h = fh.fit_transform(X_train)\n",
    "X_test_h = fh.transform(X_test)\n",
    "print(X_train_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pi_null micro test loss:\", micro_hammingloss(np.zeros(y_test.shape), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1aab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_dummy = MultiOutputClassifier(DummyClassifier())\n",
    "pi_dummy.fit(X_train, y_train)\n",
    "\n",
    "print(\"pi_dummy train loss:\", micro_hammingloss(pi_dummy.predict(X_train), y_train))\n",
    "print(\"pi_dummy test loss:\", micro_hammingloss(pi_dummy.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi0 = MultiOutputClassifier(LogisticRegression(), n_jobs=6)\n",
    "\n",
    "X_0, X_, y_0, y_ = train_test_split(X_train, y_train, test_size=.95, random_state=0)\n",
    "print('learning pi0 on', len(X_0), 'data points')\n",
    "pi0.fit(X_0, y_0)\n",
    "\n",
    "print(\"pi0 train loss:\", micro_hammingloss(pi0.predict(X_train), y_train))\n",
    "l0 = micro_hammingloss(pi0.predict(X_test), y_test)\n",
    "print(\"pi0 test loss:\", l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc726f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pistar = MultiOutputClassifier(LogisticRegressionCV(max_iter=1000, n_jobs=6))\n",
    "pistar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pi* train loss:\", micro_hammingloss(pistar.predict(X_train), y_train))\n",
    "lstar = micro_hammingloss(pistar.predict(X_test), y_test)\n",
    "print(\"pi* test loss:\", lstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb816a",
   "metadata": {},
   "source": [
    "---\n",
    "## Sequential CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_test = build_action_embeddings(X_test, labels)\n",
    "phi_train = build_action_embeddings(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51001a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_init = onp.random.normal(size=len(labels)+X_train.shape[1])\n",
    "print('beta0 test loss:', evaluate_model(beta_init, phi_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035c476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "beta_static = np.array(beta_init.copy())\n",
    "beta_dynamic = np.array(beta_init.copy())\n",
    "\n",
    "static_crm_dataset = ([],[],[],[])\n",
    "dynamic_crm_dataset = ([],[],[],[])\n",
    "\n",
    "batch = 1000\n",
    "n_episods = int(len(X_train) / batch)+1\n",
    "\n",
    "t_end = t_start = time.time()\n",
    "for episod in range(n_episods):\n",
    "    t_end = time.time()\n",
    "    \n",
    "    start = episod*batch\n",
    "    end = (episod+1)*batch\n",
    "    print('*'*10, \n",
    "          'episod: %d/%d' % (episod, n_episods), \n",
    "          'time: %ds' % (t_end - t_start), \n",
    "          '*'*10,\n",
    "          file=sys.stderr)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    X = X_train[0:end,:]\n",
    "    y = y_train[0:end,:]\n",
    "    \n",
    "    sampling_probas_static = pi0.predict_proba(X)\n",
    "    sampling_probas_static = np.array([_[:,1] for _ in sampling_probas_static]).T\n",
    "    if episod == 0:\n",
    "        sampling_probas_dynamic = sampling_probas_static\n",
    "    else:\n",
    "        phi_current = build_action_embeddings(X, labels)\n",
    "        sampling_probas_dynamic = model_predict_on_all_actions(beta_dynamic, phi_current)\n",
    "\n",
    "    beta_static, static_crm_dataset = iterate_model(\n",
    "        beta_static, X, y, sampling_probas_static, static_crm_dataset\n",
    "    )\n",
    "    l_stat = evaluate_model(beta_static, phi_test, y_test)\n",
    "    print('static   >', \n",
    "          'test loss: %.5f (vs pi0: %d%% vs pi*: %d%%)' % (l_stat, 100*l_stat/l0, 100*l_stat/lstar), \n",
    "          '|beta|=%.4f' % onp.sqrt((beta_static**2).sum()), \n",
    "          '|D_crm|:', len(static_crm_dataset[-1]),\n",
    "          file=sys.stderr)\n",
    "\n",
    "    beta_dynamic, dynamic_crm_dataset = iterate_model(\n",
    "        beta_dynamic, X, y, sampling_probas_dynamic, dynamic_crm_dataset\n",
    "    )\n",
    "    l_dyn = evaluate_model(beta_dynamic, phi_test, y_test)\n",
    "    print('dynamic  >', \n",
    "          'test loss: %.5f (vs pi0: %d%% vs pi*: %d%%)' % (l_dyn, 100*l_dyn/l0, 100*l_dyn/lstar), \n",
    "          '|beta|=%.4f' % onp.sqrt((beta_dynamic**2).sum()), \n",
    "          '|D_crm|:', len(dynamic_crm_dataset[-1]),\n",
    "          file=sys.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
