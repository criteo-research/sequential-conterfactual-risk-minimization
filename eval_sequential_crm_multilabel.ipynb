{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c25f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3299e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import jax.numpy as np\n",
    "#import jaxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad01a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da5c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d5146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize as sp_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf7812",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- //(softmax temperature ?)\n",
    "- //feedback = nb de match entre predictions et labels (par ligne)\n",
    "- //model : fix feature map : phi(X,A)(i,j) = X[i,j]*sign(A[i,j])\n",
    "- (NTH) provide gradients to optim\n",
    "- make sure loss is good\n",
    "- fix pi0 to be bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c93204",
   "metadata": {},
   "source": [
    "---\n",
    "##Â Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbaa9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='scene'\n",
    "# dataset_name='yeast'\n",
    "#dataset_name='tmc2007'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4757a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 294)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_ = load_svmlight_file(dataset_name+'_train.svm', multilabel=True)\n",
    "X_train = np.array(X_train.todense())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c48b812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 294)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test_ = load_svmlight_file(dataset_name+'_test.svm', multilabel=True)\n",
    "X_test = np.array(X_test.todense())\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795af7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labeller = MultiLabelBinarizer()\n",
    "y_train = onehot_labeller.fit_transform(y_train_).astype(int)\n",
    "y_test = onehot_labeller.transform(y_test_).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f1274f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1805, 294), (602, 294))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.vstack([X_train, X_test])\n",
    "y_all = np.vstack([y_train, y_test])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=.25, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e29fbe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'tmc_2007':\n",
    "    print(\"reducing dimension for TMC dataset\")\n",
    "    fh = GaussianRandomProjection(n_components=1000)\n",
    "    X_train = fh.fit_transform(X_train)\n",
    "    X_test = fh.transform(X_test)\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fdd9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = onehot_labeller.classes_.astype(int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7514c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.67e+03, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.34e+02,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 1.00e+00]),\n",
       " array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUL0lEQVR4nO3dfYxl9X3f8fcnu4BjO2WBHROyu81um00qsOIabTGJ0wiHFhbsZKnkWIvSeOsirZrg1KmjOOBKRrVlCbdVSVAdoq3ZGioXjIgdVg4O3mJS2ro8DATzaMIUsNkVeMcG4zg0dtf59o/723AZZnYe7swd8O/9kq7mnO/53Xu+9+zZz5w55z6kqpAk9eGHVrsBSdL4GPqS1BFDX5I6YuhLUkcMfUnqyNrVbuBo1q9fX5s3b17tNiTpVeWee+75RlVNzLbsFR36mzdvZnJycrXbkKRXlSRfnWuZp3ckqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjr+h35I5q8yV/vCrrffLyt6/KeiVpPh7pS1JHDH1J6oihL0kdMfQlqSPzhn6SvUkOJXlwRv03knwlyUNJ/u1Q/dIkU0keTXLuUH17q00luWR5n4YkaSEW8uqdTwL/Ebj2SCHJ24AdwJuq6rtJ3tDqpwI7gdOAHwP+W5KfbHf7OPCPgQPA3Un2VdXDy/VEJEnzmzf0q+r2JJtnlH8NuLyqvtvGHGr1HcD1rf5EkingjLZsqqoeB0hyfRtr6EvSGC31nP5PAv8wyZ1J/nuSf9DqG4CnhsYdaLW56i+TZHeSySST09PTS2xPkjSbpYb+WuBE4Ezgt4EbkmQ5GqqqPVW1raq2TUzM+hWPkqQlWuo7cg8An6mqAu5K8tfAeuAgsGlo3MZW4yh1SdKYLPVI/4+AtwG0C7XHAt8A9gE7kxyXZAuwFbgLuBvYmmRLkmMZXOzdN2LvkqRFmvdIP8l1wFnA+iQHgMuAvcDe9jLO7wG72lH/Q0luYHCB9jBwcVV9vz3Oe4FbgDXA3qp6aAWejyTpKBby6p0L51j0T+cY/1Hgo7PUbwZuXlR3kqRl5TtyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdmTf0k+xNcqh9S9bMZb+VpJKsb/NJcmWSqST3Jzl9aOyuJI+1267lfRqSpIVYyJH+J4HtM4tJNgHnAF8bKp/H4HtxtwK7gava2BMZfM3iW4AzgMuSnDBK45KkxZs39KvqduDZWRZdAXwAqKHaDuDaGrgDWJfkFOBcYH9VPVtVzwH7meUXiSRpZS3pnH6SHcDBqvryjEUbgKeG5g+02lz12R57d5LJJJPT09NLaU+SNIdFh36S1wIfBD60/O1AVe2pqm1VtW1iYmIlViFJ3VrKkf7fBbYAX07yJLARuDfJjwIHgU1DYze22lx1SdIYLTr0q+qBqnpDVW2uqs0MTtWcXlXPAPuAd7dX8ZwJPF9VTwO3AOckOaFdwD2n1SRJY7SQl2xeB/xv4KeSHEhy0VGG3ww8DkwB/wn4dYCqehb4CHB3u3241SRJY7R2vgFVdeE8yzcPTRdw8Rzj9gJ7F9mfJGkZ+Y5cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHFvLNWXuTHEry4FDt3yX5SpL7k3w2ybqhZZcmmUryaJJzh+rbW20qySXL/kwkSfNayJH+J4HtM2r7gTdW1U8Dfw5cCpDkVGAncFq7z+8nWZNkDfBx4DzgVODCNlaSNEbzhn5V3Q48O6P2hao63GbvADa26R3A9VX13ap6gsF35Z7RblNV9XhVfQ+4vo2VJI3RcpzT/+fA59v0BuCpoWUHWm2u+ssk2Z1kMsnk9PT0MrQnSTpipNBP8q+Bw8CnlqcdqKo9VbWtqrZNTEws18NKkoC1S71jkn8GvAM4u6qqlQ8Cm4aGbWw1jlKXJI3Jko70k2wHPgD8UlW9MLRoH7AzyXFJtgBbgbuAu4GtSbYkOZbBxd59o7UuSVqseY/0k1wHnAWsT3IAuIzBq3WOA/YnAbijqv5FVT2U5AbgYQanfS6uqu+3x3kvcAuwBthbVQ+twPORJB3FvKFfVRfOUr76KOM/Cnx0lvrNwM2L6k6StKx8R64kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSPzhn6SvUkOJXlwqHZikv1JHms/T2j1JLkyyVSS+5OcPnSfXW38Y0l2rczTkSQdzUKO9D8JbJ9RuwS4taq2Are2eYDzGHwv7lZgN3AVDH5JMPiaxbcAZwCXHflFIUkan3lDv6puB56dUd4BXNOmrwEuGKpfWwN3AOuSnAKcC+yvqmer6jlgPy//RSJJWmFLPad/clU93aafAU5u0xuAp4bGHWi1ueovk2R3kskkk9PT00tsT5I0m5Ev5FZVAbUMvRx5vD1Vta2qtk1MTCzXw0qSWHrof72dtqH9PNTqB4FNQ+M2ttpcdUnSGC019PcBR16Bswu4aaj+7vYqnjOB59tpoFuAc5Kc0C7gntNqkqQxWjvfgCTXAWcB65McYPAqnMuBG5JcBHwVeFcbfjNwPjAFvAC8B6Cqnk3yEeDuNu7DVTXz4rAkaYXNG/pVdeEci86eZWwBF8/xOHuBvYvqTpK0rHxHriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0ZKfST/KskDyV5MMl1SV6TZEuSO5NMJfl0kmPb2OPa/FRbvnlZnoEkacGWHPpJNgD/EthWVW8E1gA7gY8BV1TVTwDPARe1u1wEPNfqV7RxkqQxGvX0zlrgh5OsBV4LPA38AnBjW34NcEGb3tHmacvPTpIR1y9JWoQlh35VHQT+PfA1BmH/PHAP8K2qOtyGHQA2tOkNwFPtvofb+JOWun5J0uKNcnrnBAZH71uAHwNeB2wftaEku5NMJpmcnp4e9eEkSUNGOb3zj4Anqmq6qv4f8BngrcC6droHYCNwsE0fBDYBtOXHA9+c+aBVtaeqtlXVtomJiRHakyTNNErofw04M8lr27n5s4GHgduAd7Yxu4Cb2vS+Nk9b/sWqqhHWL0lapFHO6d/J4ILsvcAD7bH2AL8DvD/JFINz9le3u1wNnNTq7wcuGaFvSdISrJ1/yNyq6jLgshnlx4EzZhn7V8Avj7I+SdJofEeuJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjI4V+knVJbkzylSSPJPmZJCcm2Z/ksfbzhDY2Sa5MMpXk/iSnL89TkCQt1KhH+r8H/ElV/T3gTcAjDL4G8daq2grcyotfi3gesLXddgNXjbhuSdIiLTn0kxwP/DztO3Cr6ntV9S1gB3BNG3YNcEGb3gFcWwN3AOuSnLLU9UuSFm+UI/0twDTwn5P8WZJPJHkdcHJVPd3GPAOc3KY3AE8N3f9Aq71Ekt1JJpNMTk9Pj9CeJGmmUUJ/LXA6cFVVvRn4S148lQNAVRVQi3nQqtpTVduqatvExMQI7UmSZhol9A8AB6rqzjZ/I4NfAl8/ctqm/TzUlh8ENg3df2OrSZLGZMmhX1XPAE8l+alWOht4GNgH7Gq1XcBNbXof8O72Kp4zgeeHTgNJksZg7Yj3/w3gU0mOBR4H3sPgF8kNSS4Cvgq8q429GTgfmAJeaGMlSWM0UuhX1X3AtlkWnT3L2AIuHmV9kqTR+I5cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHRg79JGuS/FmSz7X5LUnuTDKV5NPtW7VIclybn2rLN4+6bknS4izHkf77gEeG5j8GXFFVPwE8B1zU6hcBz7X6FW2cJGmMRgr9JBuBtwOfaPMBfgG4sQ25BrigTe9o87TlZ7fxkqQxGfVI/3eBDwB/3eZPAr5VVYfb/AFgQ5veADwF0JY/38a/RJLdSSaTTE5PT4/YniRp2JJDP8k7gENVdc8y9kNV7amqbVW1bWJiYjkfWpK6t3aE+74V+KUk5wOvAf4W8HvAuiRr29H8RuBgG38Q2AQcSLIWOB745gjrlyQt0pKP9Kvq0qraWFWbgZ3AF6vqV4DbgHe2YbuAm9r0vjZPW/7Fqqqlrl+StHgr8Tr93wHen2SKwTn7q1v9auCkVn8/cMkKrFuSdBSjnN75G1X1p8CftunHgTNmGfNXwC8vx/okSUvjO3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0Z5YvRNyW5LcnDSR5K8r5WPzHJ/iSPtZ8ntHqSXJlkKsn9SU5frichSVqYUY70DwO/VVWnAmcCFyc5lcHXIN5aVVuBW3nxaxHPA7a2227gqhHWLUlaglG+GP3pqrq3Tf8F8AiwAdgBXNOGXQNc0KZ3ANfWwB3AuiSnLHX9kqTFW5Zz+kk2A28G7gROrqqn26JngJPb9AbgqaG7HWi1mY+1O8lkksnp6enlaE+S1Iwc+kleD/wh8JtV9e3hZVVVQC3m8apqT1Vtq6ptExMTo7YnSRoyUugnOYZB4H+qqj7Tyl8/ctqm/TzU6geBTUN339hqkqQxGeXVOwGuBh6pqv8wtGgfsKtN7wJuGqq/u72K50zg+aHTQJKkMVg7wn3fCvwq8ECS+1rtg8DlwA1JLgK+CryrLbsZOB+YAl4A3jPCuiVJS7Dk0K+q/wlkjsVnzzK+gIuXuj5J0uh8R64kdcTQl6SOjHJOX+ra5kv+eFXW++Tlb1+V9eoHg0f6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHRl76CfZnuTRJFNJLhn3+iWpZ2MN/SRrgI8D5wGnAhcmOXWcPUhSz8Z9pH8GMFVVj1fV94DrgR1j7kGSujXuL1HZADw1NH8AeMvwgCS7gd1t9jtJHh1hfeuBb4xw/yXJx+Ydsip9LYB9LY771+LY1+KM0tePz7XgFffNWVW1B9izHI+VZLKqti3HYy0n+1oc+1oc+1qc3voa9+mdg8CmofmNrSZJGoNxh/7dwNYkW5IcC+wE9o25B0nq1lhP71TV4STvBW4B1gB7q+qhFVzlspwmWgH2tTj2tTj2tThd9ZWqWonHlSS9AvmOXEnqiKEvSR15VYZ+kr1JDiV5cI7lSXJl+6iH+5OcPrRsV5LH2m3XmPv6ldbPA0m+lORNQ8uebPX7kkyOua+zkjzf1n1fkg8NLVuxj81YQF+/PdTTg0m+n+TEtmwlt9emJLcleTjJQ0neN8uYse5jC+xptfavhfQ29n1sgX2NfR9L8pokdyX5cuvr38wy5rgkn27b5M4km4eWXdrqjyY5d9ENVNWr7gb8PHA68OAcy88HPg8EOBO4s9VPBB5vP09o0yeMsa+fPbI+Bh9FcefQsieB9au0vc4CPjdLfQ3wf4C/AxwLfBk4dVx9zRj7i8AXx7S9TgFOb9M/Avz5zOc97n1sgT2t1v61kN7Gvo8tpK/V2MfaPvP6Nn0McCdw5owxvw78QZveCXy6TZ/attFxwJa27dYsZv2vyiP9qrodePYoQ3YA19bAHcC6JKcA5wL7q+rZqnoO2A9sH1dfVfWltl6AOxi8T2HFLWB7zWVFPzZjkX1dCFy3XOs+mqp6uqrubdN/ATzC4N3kw8a6jy2kp1XcvxayveayYvvYEvoayz7W9pnvtNlj2m3mK2p2ANe06RuBs5Ok1a+vqu9W1RPAFINtuGCvytBfgNk+7mHDUeqr4SIGR4pHFPCFJPdk8FEU4/Yz7c/Nzyc5rdVeEdsryWsZBOcfDpXHsr3an9VvZnA0NmzV9rGj9DRsVfaveXpbtX1svm027n0syZok9wGHGBwkzLl/VdVh4HngJJZhe73iPoahB0nexuA/5c8NlX+uqg4meQOwP8lX2pHwONwL/HhVfSfJ+cAfAVvHtO6F+EXgf1XV8F8FK769kryeQQj8ZlV9ezkfe6kW0tNq7V/z9LZq+9gC/x3Huo9V1feBv59kHfDZJG+sqlmvbS23H9Qj/bk+7mHVPwYiyU8DnwB2VNU3j9Sr6mD7eQj4LIv8k20UVfXtI39uVtXNwDFJ1vMK2F7NTmb82b3S2yvJMQyC4lNV9ZlZhox9H1tAT6u2f83X22rtYwvZZs3Y97H22N8CbuPlpwD/ZrskWQscD3yT5dhey32RYlw3YDNzX5h8Oy+9yHZXq58IPMHgAtsJbfrEMfb1txmcg/vZGfXXAT8yNP0lYPsY+/pRXnyj3hnA19q2W8vgQuQWXrzIdtq4+mrLj2dw3v9149pe7blfC/zuUcaMdR9bYE+rsn8tsLex72ML6Ws19jFgAljXpn8Y+B/AO2aMuZiXXsi9oU2fxksv5D7OIi/kvipP7yS5jsGrAdYnOQBcxuBiCFX1B8DNDF5dMQW8ALynLXs2yUcYfAYQwIfrpX/OrXRfH2JwXu73B9dkOFyDT9E7mcGfeDD4T/Bfq+pPxtjXO4FfS3IY+L/AzhrsYSv6sRkL6AvgnwBfqKq/HLrrim4v4K3ArwIPtPOuAB9kEKqrtY8tpKdV2b8W2Ntq7GML6QvGv4+dAlyTwZdK/RCDQP9ckg8Dk1W1D7ga+C9Jphj8QtrZen4oyQ3Aw8Bh4OIanCpaMD+GQZI68oN6Tl+SNAtDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXk/wPti3XWjvCz+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cf30b",
   "metadata": {},
   "source": [
    "FYI: Error rate of null policy (always predict 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105dcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.069767441860465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ab902",
   "metadata": {},
   "source": [
    "---\n",
    "## Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1279d1",
   "metadata": {},
   "source": [
    "### CRM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768c1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRMDataset(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.propensities_ = []\n",
    "        self.actions_ = []\n",
    "        self.rewards_ = []\n",
    "        self.features_ = []\n",
    "        \n",
    "        self.propensities_np = None\n",
    "        self.actions_np = None\n",
    "        self.rewards_np = None\n",
    "        self.features_np = None\n",
    "\n",
    "        self.check()\n",
    "        \n",
    "    def __str__(self):\n",
    "        if not self.propensities_np:\n",
    "            return '<CRMDataset>'\n",
    "        self._generate_numpys()\n",
    "        return '<CRMDataset propensities:%s actions:%s rewards:%s features:%s>' % (\n",
    "            self.propensities_np.shape,\n",
    "            self.actions_np.shape,\n",
    "            self.rewards_np.shape,\n",
    "            self.features_np.shape\n",
    "        )\n",
    "    \n",
    "    __repr__ = __str__\n",
    "        \n",
    "    def check(self):\n",
    "        assert len(self.features_) == len(self.propensities_) == len(self.rewards_) == len(self.actions_)\n",
    "        assert type(self.propensities_) == type(self.actions_) == type(self.rewards_) == type(self.features_) == list        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.propensities_)\n",
    "        \n",
    "    def _generate_numpys(self):\n",
    "        if self.propensities_np is not None and len(self.propensities_np) == len(self.propensities_):\n",
    "            return        \n",
    "        self.propensities_np = np.vstack(self.propensities_)\n",
    "        self.actions_np = np.vstack(self.actions_)\n",
    "        self.rewards_np = np.vstack(self.rewards_)\n",
    "        self.features_np = np.vstack(self.features_)\n",
    "        \n",
    "    @property\n",
    "    def actions(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.actions_np\n",
    "\n",
    "    @property\n",
    "    def propensities(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.propensities_np\n",
    "    \n",
    "    @property\n",
    "    def rewards(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.rewards_np\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.features_np\n",
    "        \n",
    "    def update_from_supervised_dataset(self, X, y, probas, n_samples=4, labels=labels):\n",
    "        # X is (n,d)\n",
    "        # y is (n,k)\n",
    "        # probas is (n,k)\n",
    "\n",
    "        assert len(X) == len(y) == len(probas), (len(X) , len(y) , len(probas))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            for k in range(n_samples):\n",
    "\n",
    "                chosen_actions = np.array([np.random.binomial(1, p=probas[i,j]) for j in labels])\n",
    "                self.actions_ += [chosen_actions]\n",
    "                self.propensities_ += [probas[i,:]]\n",
    "                self.features_ += [X[i,:]]\n",
    "                self.rewards_ += [sum(int(y[i,j] == chosen_actions[j]) for j in labels)]\n",
    "                \n",
    "        self._generate_numpys()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d83b97",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e499a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, beta):\n",
    "        self.d = beta.shape[0]\n",
    "        self.k = beta.shape[1]\n",
    "        self.beta_ = beta\n",
    "        \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return self.beta_\n",
    "    \n",
    "    @beta.setter\n",
    "    def beta(self, beta):\n",
    "        # beta is (d, k)\n",
    "        self.beta_ = beta.reshape(self.d, self.k)\n",
    "        \n",
    "    @staticmethod\n",
    "    def random_model(d, k):\n",
    "        beta = np.random.normal(size=(d, k))\n",
    "        return Model(beta)\n",
    "    \n",
    "    @staticmethod\n",
    "    def null_model(d, k):\n",
    "        beta = np.zeros((d, k))\n",
    "        return Model(beta)\n",
    "\n",
    "    def predict(self, features):\n",
    "        wx = np.dot(features, self.beta_)\n",
    "        return (wx > 0).astype(int)\n",
    "    \n",
    "    def predict_proba(self, features, actions):\n",
    "        wx = np.dot(features, self.beta_)\n",
    "        actions_sign = 2 * actions - 1\n",
    "        return expit(actions_sign * wx)\n",
    "    \n",
    "    def expected_hamming_loss(self, X, y):\n",
    "        y_invert = 1 - y\n",
    "        invert_probas = self.predict_proba(X, y_invert)\n",
    "        return invert_probas.sum() / (self.k * y.shape[0])    \n",
    "        \n",
    "    def crm_loss(self, crm_dataset: CRMDataset, clip: float = 1000, lambda_: float = 0):\n",
    "        n = crm_dataset.features.shape[0]\n",
    "\n",
    "        predictions = self.predict_proba(crm_dataset.features, crm_dataset.actions)\n",
    "        \n",
    "        predictions[predictions == 0] = 1. # to avoid log(0)\n",
    "        instances_with_nonzero_proba = (predictions.sum(axis=1) > 0).astype(int)\n",
    "        \n",
    "        per_instance_log_predictions = np.log(predictions).sum(axis=1)\n",
    "        per_instance_log_propensities = np.log(crm_dataset.propensities).sum(axis=1)\n",
    "        per_instance_log_propensities = np.clip(per_instance_log_propensities, -100, None) #\n",
    "        per_instance_log_importance_weights = per_instance_log_predictions - per_instance_log_propensities\n",
    "        \n",
    "        per_instance_importance_weights = np.exp(per_instance_log_importance_weights)\n",
    "        per_instance_importance_weights = per_instance_importance_weights * instances_with_nonzero_proba\n",
    "        per_instance_importance_weights = np.clip(per_instance_importance_weights, 0, clip)\n",
    "        \n",
    "        per_instance_importance_weighted_rewards = np.multiply(\n",
    "            - crm_dataset.rewards, # to make a loss\n",
    "            per_instance_importance_weights\n",
    "        )\n",
    "        \n",
    "        total_loss = per_instance_importance_weighted_rewards.mean() #sum() / per_instance_importance_weights.sum()\n",
    "        \n",
    "        return total_loss / self.k\n",
    "\n",
    "#         ips_weights = np.ones((n, self.k))\n",
    "#         non_zero_propensities = np.where(crm_dataset.propensities > 0)\n",
    "#         ips_weights[non_zero_propensities] = predictions[non_zero_propensities] / crm_dataset.propensities[non_zero_propensities]\n",
    "#         ips_weights = np.clip(ips_weights, 0, clip)\n",
    "\n",
    "#         per_instance_weights = ips_weights.sum(axis=1)\n",
    "#         ips_sum = per_instance_weights.sum()\n",
    "\n",
    "#         per_instance_weights /= ips_sum\n",
    "\n",
    "#         per_instance_loss = (self.d - crm_dataset.rewards).flatten()\n",
    "\n",
    "#         total_loss = np.dot(per_instance_loss, per_instance_weights)\n",
    "\n",
    "#         if lambda_ > 0:\n",
    "#             # POEM\n",
    "#             total_loss += lambda_ * np.std(ips_weights) / np.sqrt(n)\n",
    "\n",
    "#         return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42854657",
   "metadata": {},
   "source": [
    "### CF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87d388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(model, X, y, sampling_probas, crm_dataset: CRMDataset, \n",
    "                  samples_per_instance:int = 4, verbose=1):\n",
    "        \n",
    "    # prior_crm_dataset will get extended\n",
    "    crm_dataset.update_from_supervised_dataset(\n",
    "        X, y, sampling_probas, \n",
    "        n_samples=samples_per_instance\n",
    "    )\n",
    "    if verbose:\n",
    "        print('CRM dataset:', len(crm_dataset), end=' ', file=sys.stderr)\n",
    "        \n",
    "    def _loss(beta):\n",
    "        model.beta = beta\n",
    "        return model.crm_loss(crm_dataset)\n",
    "        \n",
    "    solution = sp_minimize(_loss, model.beta, method='L-BFGS-B')\n",
    "\n",
    "    model.beta = solution.x\n",
    "    \n",
    "    if verbose:\n",
    "        print(solution.nit, 'steps -> %.3f' % solution.fun, file=sys.stderr)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aef896",
   "metadata": {},
   "source": [
    "----\n",
    "##Â Baselines & Skylines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170d08d",
   "metadata": {},
   "source": [
    " ![Perf from CRM article](./basesky.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f30771ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_results = {\n",
    "    'scene': {\n",
    "        'pi0': 1.543, 'ips': 1.193, 'poem': 1.168, 'pi*':.659\n",
    "    },\n",
    "    'yeast': {\n",
    "        'pi0': 5.547, 'ips': 4.635, 'poem': 4.480, 'pi*':2.282\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "def stoch_hloss(pi, X_test, y_test):\n",
    "    predictions = pi.predict_proba(X_test)\n",
    "    predictions = np.array([_[:,1] for _ in predictions]).T\n",
    "    idx = np.where(y_test == 0)\n",
    "    fp = predictions[idx].sum()\n",
    "    idx = np.where(y_test == 1)\n",
    "    fn = (1-predictions[idx]).sum()\n",
    "    return (fn+fp)/(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "\n",
    "def result_table(model: Model, pi0, pistar, X_test, y_test):\n",
    "    \n",
    "    stats = paper_results[dataset_name]\n",
    "    \n",
    "    print('Baseline -- paper: %.3f -- ours (stoch.): %.3f' % (stats[\"pi0\"]/y_test.shape[1], \n",
    "                                                     stoch_hloss(pi0, X_test, y_test)))\n",
    "    print('Baseline -- paper: %.3f -- ours (deter.): %.3f' % (stats[\"pi0\"]/y_test.shape[1], \n",
    "                                                     hamming_loss(y_test, pi0.predict(X_test))))\n",
    "    print('IPS      -- paper: %.3f -- ours (stoch.): %.3f' % (stats[\"ips\"]/y_test.shape[1], \n",
    "                                                     model.expected_hamming_loss(X_test, y_test)))\n",
    "    print('POEM     -- paper: %.3f' % (stats[\"poem\"]/y_test.shape[1]))\n",
    "    print('Skyline  -- paper: %.3f -- ours (stoch.): %.3f' % (stats[\"pi*\"]/y_test.shape[1], \n",
    "                                                     stoch_hloss(pistar, X_test, y_test)))    \n",
    "    print('Skyline  -- paper: %.3f -- ours (deter.): %.3f' % (stats[\"pi*\"]/y_test.shape[1], \n",
    "                                                     hamming_loss(y_test, pistar.predict(X_test))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a96419e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegressionCV(max_iter=10000, n_jobs=6))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistar = MultiOutputClassifier(LogisticRegressionCV(max_iter=10000, n_jobs=6))\n",
    "pistar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8ad872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e06b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26c4cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning pi0 on 90 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=KNeighborsClassifier(n_neighbors=30), n_jobs=6)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0 = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=30),#penalty='l2', C=1e-9, fit_intercept=0, intercept_scaling=0), \n",
    "                            n_jobs=6)\n",
    "\n",
    "X_0, _, y_0, _ = train_test_split(X_train, y_train, test_size=.95, random_state=0)\n",
    "print('learning pi0 on', len(X_0), 'data points')\n",
    "\n",
    "pi0.fit(X_0, y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34e5b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline -- paper: 0.257 -- ours (stoch.): 0.244\n",
      "Baseline -- paper: 0.257 -- ours (deter.): 0.180\n",
      "IPS      -- paper: 0.199 -- ours (stoch.): 0.500\n",
      "POEM     -- paper: 0.195\n",
      "Skyline  -- paper: 0.110 -- ours (stoch.): 0.129\n",
      "Skyline  -- paper: 0.110 -- ours (deter.): 0.079\n"
     ]
    }
   ],
   "source": [
    "result_table(Model.null_model(X_test.shape[1], y_test.shape[1]), pi0, pistar, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd69647",
   "metadata": {},
   "source": [
    "---\n",
    "## Sequential CRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b56545",
   "metadata": {},
   "source": [
    "### Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c399eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(object):\n",
    "    \n",
    "    def __init__(self, name, ref_crm_dataset, X_test, y_test):\n",
    "        self.name = name\n",
    "        self.ref_crm_dataset = ref_crm_dataset\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.hamming_loss = []\n",
    "        self.crm_loss = []\n",
    "        self.unif_crm_loss = []\n",
    "        self.betas = []\n",
    "        self.n_samples = []\n",
    "        self.n_actions = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def update(self, model: Model, crm_dataset: CRMDataset):\n",
    "        self.betas += [model.beta]\n",
    "        self.hamming_loss += [model.expected_hamming_loss(self.X_test, self.y_test)]\n",
    "        self.crm_loss += [model.crm_loss(crm_dataset)]\n",
    "        self.unif_crm_loss += [model.crm_loss(self.ref_crm_dataset)]\n",
    "        self.n_samples += [len(crm_dataset)]\n",
    "        self.n_actions += [np.sum(crm_dataset.actions_)]\n",
    "        self.rewards += [np.sum(crm_dataset.rewards_)]\n",
    "        \n",
    "    def show_last(self):\n",
    "        print(\n",
    "            '<', self.name,\n",
    "            'Ham. loss: %.5f' % self.hamming_loss[-1], \n",
    "            'CRM loss: %.5f' % self.crm_loss[-1],\n",
    "            'CRM loss (U): %.5f' % self.unif_crm_loss[-1],\n",
    "            '|beta|=%.2f' % np.sqrt((self.betas[-1]**2).sum()), \n",
    "            'n=%d' % self.n_samples[-1],\n",
    "            '|A|=%d' % self.n_actions[-1],\n",
    "            '|R|=%d' % self.rewards[-1],\n",
    "            '>',\n",
    "            file=sys.stderr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70084dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_crm_dataset = CRMDataset().update_from_supervised_dataset(\n",
    "    X_train, y_train, \n",
    "    np.ones((X_train.shape[0], y_train.shape[1]))*.5,\n",
    "    n_samples=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51001a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta0 Exp. H. loss: 0.431\n",
      "beta0 CRM Loss (unif): -0.518\n"
     ]
    }
   ],
   "source": [
    "random_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "print('beta0 Exp. H. loss: %.3f' % random_model.expected_hamming_loss(X_test, y_test))\n",
    "print('beta0 CRM Loss (unif): %.3f' % random_model.crm_loss(ref_crm_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d66c2",
   "metadata": {},
   "source": [
    "### The Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d035c476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "****************************** PASS 1/1 ******************************\n",
      "******************** episod: 1/1 time: 0s ********************\n",
      "CRM dataset: 7220 /tmp/ipykernel_16602/4268365235.py:50: RuntimeWarning: divide by zero encountered in log\n",
      "  per_instance_log_propensities = np.log(crm_dataset.propensities).sum(axis=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m sampling_probas_static \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([_[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m sampling_probas_static])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m## optimize\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43miterate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_probas_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_crm_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples_per_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m## record\u001b[39;00m\n\u001b[1;32m     42\u001b[0m static_loss_history\u001b[38;5;241m.\u001b[39mupdate(static_model, static_crm_dataset)\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36miterate_model\u001b[0;34m(model, X, y, sampling_probas, crm_dataset, samples_per_instance, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mcrm_loss(crm_dataset)\n\u001b[0;32m---> 16\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    679\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 681\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    685\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36miterate_model.<locals>._loss\u001b[0;34m(beta)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_loss\u001b[39m(beta):\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrm_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrm_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "static_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "dynamic_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "\n",
    "static_crm_dataset = CRMDataset()\n",
    "dynamic_crm_dataset = CRMDataset()\n",
    "\n",
    "static_loss_history = LossHistory(\"Static\", ref_crm_dataset, X_test, y_test)\n",
    "dynamic_loss_history = LossHistory(\"Dynamic\", ref_crm_dataset, X_test, y_test)\n",
    "\n",
    "epochs = 1\n",
    "n_episods = 1\n",
    "batch = int(len(X_train) / n_episods)\n",
    "replays = 4\n",
    "\n",
    "t_end = t_start = time.time()\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    print('*'*30, 'PASS %d/%d'% (_+1, epochs), '*'*30, file=sys.stderr)\n",
    "    for episod in range(n_episods):\n",
    "        \n",
    "        t_end = time.time()\n",
    "        start = episod*batch\n",
    "        end = (episod+1)*batch\n",
    "        print('*'*20, 'episod: %d/%d' % (episod+1, n_episods), \n",
    "              'time: %ds' % (t_end - t_start), '*'*20, file=sys.stderr)\n",
    "        t_start = time.time()\n",
    "\n",
    "        # current slice of dataset\n",
    "        X = X_train[start:end,:]\n",
    "        y = y_train[start:end,:]\n",
    "       \n",
    "        #### static CRM \n",
    "        ## action probas\n",
    "        sampling_probas_static = pi0.predict_proba(X)\n",
    "        sampling_probas_static = np.array([_[:,1] for _ in sampling_probas_static]).T\n",
    "        ## optimize\n",
    "        iterate_model(\n",
    "            static_model, X, y, sampling_probas_static, static_crm_dataset, \n",
    "            samples_per_instance=replays,\n",
    "        )\n",
    "        ## record\n",
    "        static_loss_history.update(static_model, static_crm_dataset)\n",
    "        static_loss_history.show_last()\n",
    "        \n",
    "        #### sequential CRM \n",
    "        ## action probas\n",
    "#         if episod == 0:\n",
    "#             sampling_probas_dynamic = sampling_probas_static\n",
    "#         else:\n",
    "#             sampling_probas_dynamic = dynamic_model.predict_proba(X, y)        \n",
    "#         ## optimize\n",
    "#         iterate_model(\n",
    "#             dynamic_model, X, y, sampling_probas_dynamic, dynamic_crm_dataset,\n",
    "#             samples_per_instance=replays,\n",
    "#         )\n",
    "#         ## record\n",
    "#         dynamic_loss_history.update(dynamic_model, dynamic_crm_dataset)\n",
    "#         dynamic_loss_history.show_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6913a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table(static_model, pi0, pistar, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f233181",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ee6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "plt.title('Loss Evolution over Rollouts')\n",
    "ax.set_xlabel('Rollouts')\n",
    "ax.set_ylabel('CRM Loss')\n",
    "ax.plot(static_loss_history.crm_loss, '--', label='CRM loss (static)')\n",
    "ax.plot(dynamic_loss_history.crm_loss, '--', label='CRM loss (dynamic)')\n",
    "ax.plot(static_loss_history.unif_crm_loss, '--', label='unif. CRM loss (static)')\n",
    "ax.plot(dynamic_loss_history.unif_crm_loss, '--', label='unif. CRM loss (dynamic)')\n",
    "ax.legend(loc='upper right')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(static_loss_history.hamming_loss, label='Hamming loss (static)')\n",
    "ax2.plot(dynamic_loss_history.hamming_loss, label='Hamming loss (dynamic)')\n",
    "ax2.set_ylabel('Hamming Loss')\n",
    "ax2.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Action')\n",
    "plt.plot(expit(beta_static.mean(axis=0)),'--', label='static')\n",
    "plt.plot(expit(beta_dynamic.mean(axis=0)),'--', label='dynamic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d44929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Feature')\n",
    "plt.plot(expit(beta_static.mean(axis=1)),'--', label='static')\n",
    "plt.plot(expit(beta_dynamic.mean(axis=1)),'--', label='dynamic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Sampling Probas per Action')\n",
    "plt.plot(sampling_probas_static.mean(axis=0),'--', label='static')\n",
    "plt.plot(sampling_probas_dynamic.mean(axis=0),'--', label='dynamic')\n",
    "plt.plot(y_test.mean(axis=0), label='label average', alpha=.5)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
