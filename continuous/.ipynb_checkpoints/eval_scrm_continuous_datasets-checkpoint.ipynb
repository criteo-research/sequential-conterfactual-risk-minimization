{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced34c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be42522",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca167277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from matplotlib.lines import Line2D\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba53686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import get_dataset_by_name\n",
    "# Data, modelling and hyperparameters setup\n",
    "\n",
    "dataset_name = 'noisymoons'\n",
    "dataset = get_dataset_by_name(dataset_name)\n",
    "actions, features, losses, propensities, potentials = dataset.sample_logged_data(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c99f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized(X):\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "def plot_dataset(features, potentials, dataset_name):\n",
    "\n",
    "    # Utilities\n",
    "    colormap = cm.get_cmap('PRGn')\n",
    "    custom_lines_p = [Line2D([0], [0], color=colormap(0.), lw=4),\n",
    "                Line2D([0], [0], color=colormap(.5), lw=4),\n",
    "                Line2D([0], [0], color=colormap(1.), lw=4)]\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    \n",
    "    \n",
    "    # Original data\n",
    "    standardized_potentials = get_standardized(potentials)\n",
    "    plt.scatter(features[:, 0], features[:, 1], s=10, color=colormap(standardized_potentials))\n",
    "\n",
    "    plt.text(.99, .01, dataset_name,\n",
    "             transform=plt.gca().transAxes, \n",
    "             size=15,\n",
    "             horizontalalignment='right')\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "#     axs[0].set_xlim(-0.2,1.2)\n",
    "#     axs[0].set_ylim(-0.2,1.2)\n",
    "\n",
    "    plt.title('Ground truth data')\n",
    "    plt.legend(custom_lines_p, ['Low', 'Medium', 'High'], title='$p \\sim P \\ | \\ X$', loc=\"upper right\",\n",
    "              fancybox=True)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c056f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(features, potentials, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e90220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(object):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.crm_loss = []\n",
    "        self.online_loss = []\n",
    "        self.betas = []\n",
    "        self.n_samples = []\n",
    "        self.n_actions = []\n",
    "        self.cumulated_loss = []\n",
    "        self.regret = []\n",
    "        \n",
    "    def update(self, beta, online_loss, regret, crm_loss, n_samples):\n",
    "        self.betas += [beta]\n",
    "        self.online_loss += [online_loss]\n",
    "        self.crm_loss += [crm_loss]\n",
    "        self.n_samples += [n_samples]\n",
    "        self.cumulated_loss += [np.sum(self.online_loss)]\n",
    "        self.regret += [np.sum(self.regret) + regret*n_samples] \n",
    "        \n",
    "    def show_last(self):\n",
    "        print(\n",
    "            '<', self.name,\n",
    "            'CRM loss: %.5f' % self.crm_loss[-1],\n",
    "            'Online loss: %.5f' % self.online_loss[-1],\n",
    "            '|beta|=%.2f' % np.sqrt((self.betas[-1]**2).sum()), \n",
    "            'n=%d' % sum(self.n_samples),\n",
    "            '>',\n",
    "            file=sys.stderr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8800c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, name, random_seed):\n",
    "        self.name = name\n",
    "        self.rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    def create_start_parameter(self, dataset):\n",
    "        d = dataset.dimension\n",
    "        if self.name == 'linear':\n",
    "#             return self.rng.normal(scale=0.1, size=d + 2)\n",
    "            return self.rng.normal(scale=0.1, size=d + 1)\n",
    "\n",
    "        elif self.name == 'polynomial':\n",
    "            return self.rng.normal(scale=0.1, size=d ** 2 + d + 1)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def _linear_modelling(self, parameter, features):\n",
    "#         intercept_coeff, mean_coeff, var = parameter[0], parameter[1:-1], parameter[-1]\n",
    "        intercept_coeff, mean_coeff = parameter[0], parameter[1:]\n",
    "        mean = jnp.dot(features, mean_coeff) + intercept_coeff\n",
    "        return mean, None\n",
    "    \n",
    "    def _polynomial_modelling(self, parameter, features):\n",
    "        n = features.shape[1]\n",
    "#         intercept, coeff_lin, coeff_kern, var = parameter[0], parameter[1:n + 1], parameter[n + 1:-1], parameter[-1]\n",
    "        intercept, coeff_lin, coeff_kern = parameter[0], parameter[1:n + 1], parameter[n + 1:]\n",
    "    \n",
    "        m_linear = jnp.dot(features, coeff_lin) + intercept\n",
    "        f = jnp.einsum('ij,ih->ijh', features, features).reshape(features.shape[0], -1)\n",
    "        m_kern = jnp.dot(f, coeff_kern)\n",
    "        mean = m_kern + m_linear\n",
    "        return mean, None\n",
    "    \n",
    "    def get_parameter(self, parameter, features):\n",
    "        if self.name == 'linear':\n",
    "            return self._linear_modelling(parameter, features)\n",
    "        elif self.name == 'polynomial':\n",
    "            return self._polynomial_modelling(parameter, features)\n",
    "        else:\n",
    "            return  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20f2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxopt\n",
    "\n",
    "def pdf(loc, x):\n",
    "    scale = logging_scale\n",
    "    return 1/(scale * jnp.sqrt(2*jnp.pi)) * jnp.exp(-((x - loc)/scale)**2/2)\n",
    "\n",
    "class Estimator():\n",
    "    def __init__(self, contextual_modelling, mode='conservative', lbd=0.1):\n",
    "        self.contextual_modelling = contextual_modelling\n",
    "        self.mode = mode\n",
    "        bonus = 1 if self.mode == 'conservative' else -1\n",
    "        self.lbd = bonus * lbd\n",
    "        \n",
    "    def objective_function(self, param, actions, contexts, losses, propensities):\n",
    "        \n",
    "        contextual_param, _ = self.contextual_modelling.get_parameter(param, contexts)\n",
    "        propensities = jnp.clip(propensities, 1e-5, None)\n",
    "        importance_weights = pdf(contextual_param, actions)/propensities\n",
    "        mean = jnp.mean(losses * importance_weights)\n",
    "        std = jnp.std(losses * importance_weights)\n",
    "        return mean + self.lbd * std\n",
    "    \n",
    "    \n",
    "def optimize(loss_fun, init_parameter, args):\n",
    "\n",
    "    lbfgsb = jaxopt.ScipyMinimize(fun=loss_fun, method=\"L-BFGS-B\").run(init_parameter, *args)\n",
    "    lbfgs_sol = lbfgsb.params\n",
    "    lbfgs_fun_val = lbfgsb.state.fun_val\n",
    "    \n",
    "    return lbfgs_sol, lbfgs_fun_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9ff45",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f029a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_mu = 3\n",
    "logging_scale = 0.3\n",
    "\n",
    "\n",
    "def get_logging_data(n_samples, dataset, random_seed=123):\n",
    "\n",
    "    actions, contexts, losses, propensities, potentials = dataset.sample_logged_data(n_samples)\n",
    "#     losses = -rewards\n",
    "#     loss = np.mean(losses)\n",
    "# #     epsilon = 0.9\n",
    "# #     logging_loss_threshold = loss*(1+epsilon)\n",
    "    logging_data = actions, contexts, losses, propensities\n",
    "\n",
    "    return logging_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d8ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def online_evaluation(optimized_param, contextual_modelling, dataset, random_seed):\n",
    "    \n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    contexts, potentials = dataset.test_data\n",
    "    contextual_param, _ = contextual_modelling.get_parameter(optimized_param, contexts)\n",
    "    size = contexts.shape[0]\n",
    "    rewards = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        sampled_actions = rng.normal(contextual_param, logging_scale, size)\n",
    "        rewards += [- dataset.get_losses_from_actions(potentials, sampled_actions)]\n",
    "        \n",
    "    rewards_array = np.stack(rewards, axis=0)\n",
    "    var_pi = np.mean(np.var(rewards_array, axis=0))\n",
    "    var_context = np.var(np.mean(rewards_array, axis=1))\n",
    "    return - np.mean(rewards_array), np.std(np.mean(rewards_array, axis=0))\n",
    "    \n",
    "def start_experiment(random_seed, dataset, name):\n",
    "    print(\n",
    "        '***', 'EXPERIMENT', name,\n",
    "        'Random seed: %i' % random_seed,\n",
    "        'Dataset: %s' % dataset.name,\n",
    "        '***',\n",
    "        file=sys.stderr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61ff96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10\n",
    "n_0 = 10\n",
    "T = n_0 * (2**(M+1)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983fac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20470"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5813f4",
   "metadata": {},
   "source": [
    "### Single round CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "\n",
    "\n",
    "dataset_name = 'noisymoons'\n",
    "settings = {\n",
    "    'lambda': 0.1,\n",
    "    'contextual_modelling': 'linear'\n",
    "}\n",
    "\n",
    "\n",
    "crm_histories = []\n",
    "\n",
    "optimal_mu = dataset.get_optimal_parameter(settings['contextual_modelling'])\n",
    "\n",
    "\n",
    "def crm_experiment(random_seed, dataset_name, settings):\n",
    "    \n",
    "    dataset = get_dataset_by_name(dataset_name, random_seed)\n",
    "\n",
    "    start_experiment(random_seed, dataset, 'CRM')\n",
    "    # Model setting\n",
    "    contextual_modelling = Model(settings['contextual_modelling'], random_seed)\n",
    "    estimator = Estimator(contextual_modelling, 'conservative', settings['lambda'])\n",
    "    crm_loss_history = LossHistory(\"CRM\")\n",
    "\n",
    "    n_samples = n_0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logging data\n",
    "    mu = contextual_modelling.create_start_parameter(dataset)\n",
    "    logging_data = get_logging_data(n_samples, dataset, random_seed)\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        # Optimization \n",
    "        init_parameter = jnp.array(mu, dtype='float32')\n",
    "        args = logging_data\n",
    "        optimized_mu, loss_crm = optimize(estimator.objective_function, init_parameter, args)        \n",
    "\n",
    "        ### New logging data\n",
    "        loss_crm = loss_crm._value\n",
    "        \n",
    "        n_samples *= 2\n",
    "        contexts, potentials = dataset.sample_data(n_samples)\n",
    "        contextual_param, _ = contextual_modelling.get_parameter(mu, contexts)\n",
    "        actions = rng.normal(contextual_param, logging_scale, n_samples)\n",
    "        losses = dataset.get_losses_from_actions(potentials, actions)\n",
    "        propensities = norm(loc=contextual_param, scale=logging_scale).pdf(actions)\n",
    "        logging_data = actions, contexts, losses, propensities\n",
    "\n",
    "        ## Record \n",
    "        online_loss, _ = online_evaluation(optimized_mu._value, contextual_modelling, dataset, random_seed)\n",
    "        regret = online_loss - online_evaluation(optimal_mu, contextual_modelling, dataset, random_seed)\n",
    "    \n",
    "        crm_loss_history.update(optimized_mu, online_loss, regret, loss_crm, n_samples)\n",
    "        crm_loss_history.show_last()\n",
    "        \n",
    "    return crm_loss_history\n",
    "\n",
    "\n",
    "for random_seed in range(10):\n",
    "    crm_loss_history = crm_experiment(random_seed, dataset_name, settings)\n",
    "    crm_histories.append(crm_loss_history)\n",
    "\n",
    "\n",
    "crm_losses = np.array([crm_loss_history.crm_loss for crm_loss_history in crm_histories])\n",
    "mean_crm_losses = np.mean(crm_losses, axis=0)\n",
    "\n",
    "crm_online_losses = np.array([crm_loss_history.online_loss for crm_loss_history in crm_histories])\n",
    "mean_crm_online_losses = np.mean(crm_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e397929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts, potentials = dataset.test_data\n",
    "# contextual_optimal_param, _ = contextual_modelling.get_parameter(optimal_mu, contexts)\n",
    "# contextual_param, _ = contextual_modelling.get_parameter(mu, contexts)\n",
    "\n",
    "# sampled_actions = rng.normal(contextual_param, logging_scale, size)\n",
    "# pdf(contextual_param, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af873c4",
   "metadata": {},
   "source": [
    "### Sequential CRM - Myopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d583083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrm_m_histories = []\n",
    "\n",
    "\n",
    "def scrm_myopic_experiment(random_seed, dataset_name, settings):\n",
    "    \n",
    "    dataset = get_dataset_by_name(dataset_name, random_seed)\n",
    "    start_experiment(random_seed, dataset, 'SCRM Myopic')\n",
    "    \n",
    "    # Model setting\n",
    "    contextual_modelling = Model(settings['contextual_modelling'], random_seed)\n",
    "    estimator = Estimator(contextual_modelling, 'conservative', settings['lambda'])\n",
    "    scrm_m_loss_history = LossHistory(\"SCRM-M\")\n",
    "\n",
    "    n_samples = 10\n",
    "    \n",
    "    # Logging data\n",
    "    mu = contextual_modelling.create_start_parameter(dataset)\n",
    "    logging_data = get_logging_data(n_samples, dataset, random_seed)\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    optimal_mu = dataset.get_optimal_parameter()\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        # Optimization \n",
    "        init_parameter = jnp.array(mu, dtype='float32')\n",
    "        args = logging_data\n",
    "        optimized_mu, loss_crm = optimize(estimator.objective_function, init_parameter, args)        \n",
    "\n",
    "        ### New logging data\n",
    "        mu = optimized_mu._value\n",
    "        loss_crm = loss_crm._value\n",
    "        \n",
    "        n_samples *= 2\n",
    "        contexts, potentials = dataset.sample_data(n_samples)\n",
    "        contextual_param, _ = contextual_modelling.get_parameter(mu, contexts)\n",
    "        actions = rng.normal(contextual_param, logging_scale, n_samples)\n",
    "        losses = dataset.get_losses_from_actions(potentials, actions)\n",
    "        propensities = norm(loc=contextual_param, scale=logging_scale).pdf(actions)\n",
    "        logging_data = actions, contexts, losses, propensities\n",
    "\n",
    "        ## Record \n",
    "        online_loss, _ = online_evaluation(mu, contextual_modelling, dataset, random_seed)\n",
    "        regret = online_loss - online_evaluation(optimal_mu, contextual_modelling, dataset, random_seed)\n",
    "        \n",
    "        scrm_m_loss_history.update(optimized_mu, online_loss, regret, loss_crm, n_samples)\n",
    "        scrm_m_loss_history.show_last()\n",
    "    \n",
    "    return scrm_m_loss_history\n",
    "\n",
    "for random_seed in range(10):\n",
    "    scrm_m_loss_history = scrm_myopic_experiment(random_seed, dataset_name, settings)\n",
    "    scrm_m_histories.append(scrm_m_loss_history)\n",
    "\n",
    "scrm_m_losses = np.array([scrm_m_loss_history.crm_loss for scrm_m_loss_history in scrm_m_histories])\n",
    "mean_scrm_m_losses = np.mean(scrm_m_losses, axis=0)\n",
    "\n",
    "scrm_m_online_losses = np.array([scrm_m_loss_history.online_loss for scrm_m_loss_history in scrm_m_histories])\n",
    "mean_scrm_m_online_losses = np.mean(scrm_m_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7badc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65cc7dbf",
   "metadata": {},
   "source": [
    "## Sequential with past information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f52be",
   "metadata": {},
   "source": [
    "### Naive Multi IPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d315f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utilities\n",
    "\n",
    "def get_all_data(logging_actions, logging_contexts, logging_losses, logging_propensities):\n",
    "    all_logging_actions = np.concatenate(logging_actions)\n",
    "    all_logging_contexts = np.concatenate(logging_contexts)\n",
    "    all_logging_losses = np.concatenate(logging_losses)\n",
    "    all_logging_propensities = np.concatenate(logging_propensities)\n",
    "    return all_logging_actions, all_logging_contexts, all_logging_losses, all_logging_propensities\n",
    "\n",
    "def update_past_data(data, samples):\n",
    "    return np.hstack([data, samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d883c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrm_nmips_histories = []\n",
    "\n",
    "def scrm_nmips_experiment(random_seed, dataset_name, settings):\n",
    "\n",
    "    dataset = get_dataset_by_name(dataset_name, random_seed)\n",
    "    start_experiment(random_seed, dataset, 'Naive MultiIPS SCRM')\n",
    "    \n",
    "    # Model setting\n",
    "    contextual_modelling = Model(settings['contextual_modelling'], random_seed)\n",
    "    estimator = Estimator(contextual_modelling, 'conservative', settings['lambda'])\n",
    "    scrm_nmips_loss_history = LossHistory(\"SCRM-NMIPS\")\n",
    "    \n",
    "    n_samples = 10\n",
    "    \n",
    "    # Logging data\n",
    "    mu = contextual_modelling.create_start_parameter(dataset)\n",
    "    logging_data = get_logging_data(n_samples, dataset, random_seed)\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    # Setting\n",
    "    all_actions, all_contexts, all_losses, all_propensities = logging_data\n",
    "    \n",
    "    optimal_mu = dataset.get_optimal_parameter()\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        ### Logging data with mixture propensities\n",
    "        logging_data = all_actions, all_contexts, all_losses, all_propensities\n",
    "\n",
    "        # Optimization \n",
    "        init_parameter = jnp.array(mu, dtype='float32')\n",
    "        args = logging_data\n",
    "        optimized_mu, loss_crm = optimize(estimator.objective_function, init_parameter, args)        \n",
    "        \n",
    "        ### New logging data\n",
    "        n_samples *= 2\n",
    "        mu = optimized_mu._value\n",
    "        loss_crm = loss_crm._value\n",
    "        \n",
    "        contexts, potentials = dataset.sample_data(n_samples)\n",
    "        contextual_param, _ = contextual_modelling.get_parameter(mu, contexts)\n",
    "        actions = rng.normal(contextual_param, logging_scale, n_samples)\n",
    "        losses = dataset.get_losses_from_actions(potentials, actions)\n",
    "        propensities = norm(loc=contextual_param, scale=logging_scale).pdf(actions)\n",
    "        logging_data = actions, contexts, losses, propensities\n",
    "        \n",
    "        ## Record \n",
    "        online_loss, _ = online_evaluation(mu, contextual_modelling, dataset, random_seed)\n",
    "        scrm_nmips_loss_history.update(optimized_mu, online_loss, loss_crm, n_samples)\n",
    "        scrm_nmips_loss_history.show_last()\n",
    "        \n",
    "        all_actions = update_past_data(all_actions, actions)\n",
    "        all_contexts = np.vstack([all_contexts, contexts])\n",
    "        all_losses = update_past_data(all_losses, losses)\n",
    "        all_propensities = update_past_data(all_propensities, propensities)\n",
    "        \n",
    "    return scrm_nmips_loss_history\n",
    "\n",
    "for random_seed in range(10):\n",
    "    scrm_nmips_loss_history = scrm_nmips_experiment(random_seed, dataset_name, settings)\n",
    "    scrm_nmips_histories.append(scrm_nmips_loss_history)\n",
    "\n",
    "scrm_nmips_losses = np.array([scrm_nmips_loss_history.crm_loss for scrm_nmips_loss_history in scrm_nmips_histories])\n",
    "mean_scrm_nmips_losses = np.nanmean(scrm_nmips_losses, axis=0)\n",
    "\n",
    "scrm_nmips_online_losses = np.array([scrm_nmips_loss_history.online_loss for scrm_nmips_loss_history in scrm_nmips_histories])\n",
    "mean_scrm_nmips_online_losses = np.nanmean(scrm_nmips_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d922a55",
   "metadata": {},
   "source": [
    "### Multi data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiple IPS\n",
    "\n",
    "def get_omega_weights(params, all_actions, all_contexts, all_propensities):\n",
    "    distributions = []\n",
    "    for param in params:\n",
    "        contextual_param, _ = linear_modelling(param, all_contexts)\n",
    "        distributions.append(norm(loc=contextual_param, scale=logging_scale).pdf)\n",
    "    pi_t = np.array([distribution(all_actions) for distribution in distributions])\n",
    "    n_pi_t = n_samples * pi_t\n",
    "    sum_n_pi_t = np.sum(n_pi_t, axis=0)\n",
    "    all_omegas = all_propensities / sum_n_pi_t\n",
    "    return all_omegas\n",
    "\n",
    "def multi_ips_mean(param, all_actions, all_contexts, all_losses, all_propensities, all_omegas):\n",
    "    \n",
    "    # Importance weights\n",
    "    contextual_param, _ = linear_modelling(param, all_contexts)\n",
    "    importance_weights = pdf(contextual_param, all_actions)/all_propensities\n",
    "    all_importance_weights = pdf(contextual_param, all_actions)/all_propensities\n",
    "    \n",
    "    # Omega weight\n",
    "    return np.sum(all_omegas * all_losses * all_importance_weights)\n",
    "\n",
    "class MixtureEstimator():\n",
    "    def __init__(self, contextual_modelling, mode='conservative', lbd=0.1):\n",
    "        self.contextual_modelling = contextual_modelling\n",
    "        self.mode = mode\n",
    "        bonus = 1 if self.mode == 'conservative' else -1\n",
    "        self.lbd = bonus * lbd\n",
    "        self.params = []\n",
    "        self.rollouts_n_samples = []\n",
    "        \n",
    "    def get_mixture_logging_propensities(self, all_policy_samples, all_contexts):\n",
    "        distributions = []\n",
    "\n",
    "        for param in self.params:\n",
    "            contextual_param, _ = self.contextual_modelling.get_parameter(param, all_contexts)\n",
    "            distributions.append(norm(loc=contextual_param, scale=logging_scale).pdf)\n",
    "        pi_t = np.array([distribution(all_policy_samples) for distribution in distributions])\n",
    "        alpha_t = self.rollouts_n_samples/ np.sum(self.rollouts_n_samples)\n",
    "        mixture_logging_propensities = np.sum(alpha_t * pi_t, axis=0)\n",
    "        return mixture_logging_propensities\n",
    "        \n",
    "    def objective_function(self, param, actions, contexts, losses, mixture_propensities):\n",
    "        contextual_param, _ = self.contextual_modelling.get_parameter(param, contexts)\n",
    "        mixture_propensities = jnp.clip(mixture_propensities, 1e-5, None)\n",
    "        mixture_importance_weights = pdf(contextual_param, actions)/mixture_propensities\n",
    "        mixture_mean = jnp.mean(losses * mixture_importance_weights)\n",
    "        mixture_std = jnp.sqrt(jnp.sum(jnp.cov(losses * mixture_importance_weights)))\n",
    "        return mixture_mean + self.lbd * mixture_std\n",
    "    \n",
    "    def update(self, param, rollout_n_samples):\n",
    "        self.params.append(param)\n",
    "        self.rollouts_n_samples = np.concatenate([self.rollouts_n_samples, [[rollout_n_samples]]], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d4424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scrm_mips_histories = []\n",
    "\n",
    "def scrm_mixture_mips_experiment(random_seed, dataset_name, settings):\n",
    "\n",
    "    dataset = get_dataset_by_name(dataset_name, random_seed)\n",
    "    start_experiment(random_seed, dataset, 'Mixture MultiIPS SCRM')\n",
    "    \n",
    "    # Model setting\n",
    "    contextual_modelling = Model(settings['contextual_modelling'], random_seed)\n",
    "    estimator = MixtureEstimator(contextual_modelling, 'conservative', settings['lambda'])\n",
    "    scrm_mmips_loss_history = LossHistory(\"SCRM-MMIPS\")\n",
    "    \n",
    "    n_samples = 10\n",
    "    \n",
    "    # Logging data\n",
    "    mu = contextual_modelling.create_start_parameter(dataset)\n",
    "    logging_data = get_logging_data(n_samples, dataset, random_seed)\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    # Setting\n",
    "    estimator.params.append(mu)\n",
    "    estimator.rollouts_n_samples = np.array([[n_samples]])\n",
    "    all_actions, all_contexts, all_losses, all_propensities = logging_data\n",
    "\n",
    "    for m in range(M):\n",
    "\n",
    "        mixture_logging_propensities = estimator.get_mixture_logging_propensities(all_actions, all_contexts)\n",
    "\n",
    "        ### Logging data with mixture propensities\n",
    "        logging_data = all_actions, all_contexts, all_losses, mixture_logging_propensities\n",
    "\n",
    "        # Optimization \n",
    "        init_parameter = jnp.array(mu, dtype='float32')\n",
    "        args = logging_data\n",
    "        optimized_mu, loss_crm = optimize(estimator.objective_function, init_parameter, args)        \n",
    "        \n",
    "        ### New logging data\n",
    "        n_samples *= 2\n",
    "        mu = optimized_mu._value\n",
    "        loss_crm = loss_crm._value\n",
    "        estimator.update(optimized_mu, n_samples)\n",
    "        \n",
    "        contexts, potentials = dataset.sample_data(n_samples)\n",
    "        contextual_param, _ = contextual_modelling.get_parameter(mu, contexts)\n",
    "        actions = rng.normal(contextual_param, logging_scale, n_samples)\n",
    "        losses = dataset.get_losses_from_actions(potentials, actions)\n",
    "        propensities = norm(loc=contextual_param, scale=logging_scale).pdf(actions)\n",
    "        logging_data = actions, contexts, losses, propensities\n",
    "        \n",
    "        ## Record \n",
    "        online_loss, _ = online_evaluation(mu, contextual_modelling, dataset, random_seed)\n",
    "        regret = online_loss - online_evaluation(optimal_mu, contextual_modelling, dataset, random_seed)\n",
    "        \n",
    "        scrm_mmips_loss_history.update(optimized_mu, online_loss, loss_crm, n_samples)\n",
    "        scrm_mmips_loss_history.show_last()\n",
    "        \n",
    "        all_actions = update_past_data(all_actions, actions)\n",
    "        all_contexts = np.vstack([all_contexts, contexts])\n",
    "        all_losses = update_past_data(all_losses, losses)\n",
    "        all_propensities = update_past_data(all_propensities, propensities)\n",
    "        \n",
    "    return scrm_mmips_loss_history\n",
    "\n",
    "for random_seed in range(10):\n",
    "    scrm_mmips_loss_history = scrm_mixture_mips_experiment(random_seed, dataset_name, settings)\n",
    "    scrm_mips_histories.append(scrm_mmips_loss_history)\n",
    "        \n",
    "scrm_mmips_losses = np.array([scrm_mmips_loss_history.crm_loss for scrm_mmips_loss_history in scrm_mips_histories])\n",
    "mean_scrm_mmips_losses = np.nanmean(scrm_mmips_losses, axis=0)\n",
    "\n",
    "scrm_mmips_online_losses = np.array([scrm_mmips_loss_history.online_loss for scrm_mmips_loss_history in scrm_mips_histories])\n",
    "mean_scrm_mmips_online_losses = np.nanmean(scrm_mmips_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939738f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcdf18b8",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "plt.title('Loss Evolution over Rollouts')\n",
    "ax.set_xlabel('Rollouts')\n",
    "ax.set_ylabel('CRM Loss')\n",
    "ax.plot(mean_crm_losses, '--', label='CRM')\n",
    "ax.plot(mean_scrm_m_losses, '--', label='SCRM-M')\n",
    "ax.plot(mean_scrm_nmips_losses, '--', label='SCRM-NMIPS')\n",
    "ax.plot(mean_scrm_mmips_losses, '--', label='SCRM-MMIPS')\n",
    "ax.set_ylim(-0.8, -0.4)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "ax2.plot(mean_crm_online_losses, '-', label='CRM')\n",
    "ax2.plot(mean_scrm_m_online_losses, '-.', label='SCRM-M')\n",
    "ax2.plot(mean_scrm_nmips_online_losses, '-.', label='SCRM-NMIPS')\n",
    "ax2.plot(mean_scrm_mmips_online_losses,'-.', label='SCRM-MMIPS')\n",
    "ax2.plot(batch_kucb_online_losses, label='Batch-KUCB')\n",
    "ax2.plot(batch_sbpe_online_losses, label='SBPE')\n",
    "\n",
    "ax2.set_ylabel('Online Loss')\n",
    "ax2.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22dcbfc",
   "metadata": {},
   "source": [
    "# Batch bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e39e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def sqeuclidean_distance(x, y):\n",
    "    return jnp.sum((x-y)**2)\n",
    "\n",
    "# RBF Kernel\n",
    "@jax.jit\n",
    "def rbf_kernel(gamma, x, y):\n",
    "    return jnp.exp( - gamma * sqeuclidean_distance(x, y))\n",
    "\n",
    "# Exponential Kernel\n",
    "@jax.jit\n",
    "def exp_kernel(gamma, x, y):\n",
    "    return jnp.exp( - gamma * jnp.sqrt(sqeuclidean_distance(x, y)))\n",
    "\n",
    "@jax.jit\n",
    "def polynomial_kernel(dimension, x, y):\n",
    "    return (jnp.dot(x,y)+1)**dimension\n",
    "\n",
    "def gram(func, params, x, y):\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(params, x1, y1))(y))(x)\n",
    "\n",
    "class Kernel:\n",
    "\n",
    "    def __init__(self, settings):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self._param = 0.1\n",
    "\n",
    "    def gram_matrix(self, states):\n",
    "        return self._pairwise(states, states)\n",
    "\n",
    "    def evaluate(self, state1, state2):\n",
    "        return self._pairwise(state1, state2)\n",
    "\n",
    "    def _pairwise(self, X1, X2):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Gaussian(Kernel):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        super(Gaussian, self).__init__(*args)\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self._std = self._param\n",
    "\n",
    "    def _pairwise(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X1 (np.ndarray)\n",
    "            X2 (np.ndarray)\n",
    "        \"\"\"\n",
    "        return gram(rbf_kernel, 1/(2* self._std ** 2),X1,X2)\n",
    "\n",
    "class Exponential(Kernel):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        super(Exponential, self).__init__(*args)\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self._alpha = 10\n",
    "\n",
    "    def _pairwise(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X1 (np.ndarray)\n",
    "            X2 (np.ndarray)\n",
    "        \"\"\"\n",
    "        return gram(exp_kernel, self._alpha,X1,X2)\n",
    "    \n",
    "class Polynomial(Kernel):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        super(Polynomial, self).__init__(*args)\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self._dimension = 2\n",
    "\n",
    "    def _pairwise(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X1 (np.ndarray)\n",
    "            X2 (np.ndarray)\n",
    "        \"\"\"\n",
    "        return gram(polynomial_kernel, self._dimension, X1,X2)\n",
    "    \n",
    "class KernelUCB:\n",
    "\n",
    "    def __init__(self, settings, kernel):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self.rng = np.random.RandomState(123)\n",
    "        self.reg_lambda = settings['reg_lambda']\n",
    "        self.kernel = kernel\n",
    "        self.settings = settings\n",
    "\n",
    "    def get_story_data(self):\n",
    "        return self.past_states, self.rewards\n",
    "\n",
    "    def set_gram_matrix(self):\n",
    "        K = self.kernel.gram_matrix(self.past_states)\n",
    "        K += self.reg_lambda * jnp.eye(K.shape[0])\n",
    "        self.K_matrix_inverse = jnp.linalg.inv(K)\n",
    "        \n",
    "    def instantiate(self, env):\n",
    "        self.action_anchors = env.get_anchor_points()\n",
    "        context, label = env.sample_data(n=1)\n",
    "        idx = self.rng.choice(self.action_anchors.shape[0])\n",
    "        action = np.array([self.action_anchors[idx]])\n",
    "        state = self.get_state(context, action)\n",
    "        reward = env.sample_reward(action, label)\n",
    "        self.past_states = jnp.array(self.get_state(context, action))\n",
    "        self.rewards = jnp.array([reward])\n",
    "        self.set_gram_matrix()\n",
    "        \n",
    "    def set_beta(self):\n",
    "        self.beta_t = 0.1\n",
    "\n",
    "    def get_upper_confidence_bound(self, state, K_matrix_inverse, S, rewards):\n",
    "        K_S_s = self.kernel.evaluate(S, state)\n",
    "        mean = jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, rewards))\n",
    "        K_ss = self.kernel.evaluate(state, state)\n",
    "        std = (1/self.reg_lambda)*(K_ss - jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, K_S_s)))\n",
    "        ucb = mean + self.beta_t * jnp.sqrt(std)\n",
    "        return jnp.squeeze(ucb)\n",
    "\n",
    "    def sample_action(self, context):\n",
    "        self.set_beta()\n",
    "        S, rewards = self.get_story_data()\n",
    "        args = self.K_matrix_inverse, S, rewards\n",
    "        return self.continuous_inference(context, args)\n",
    "\n",
    "    def continuous_inference(self, context, args):\n",
    "        nb_gradient_steps = 0\n",
    "        if nb_gradient_steps == 0:\n",
    "            return self.discrete_inference(context,args)\n",
    "        else:\n",
    "            def func(action):\n",
    "                state = self.get_state(context, action)\n",
    "                return self.get_upper_confidence_bound(state, *args)\n",
    "\n",
    "            a0 = self.discrete_inference(context, args)\n",
    "            max_hessian_eigenvalue = jnp.max(jsp.linalg.eigh(hessian(func)(a0), eigvals_only=True))\n",
    "            step_size = jnp.nan_to_num(1 / max_hessian_eigenvalue)\n",
    "            a_t = a0\n",
    "            for _ in range(nb_gradient_steps):\n",
    "                gradient = jnp.nan_to_num(grad(func)(a_t))\n",
    "                a_t -= step_size * gradient\n",
    "            return a_t\n",
    "\n",
    "    def get_state(self, context, action):\n",
    "        context, action = context.reshape((1, -1)), action.reshape((1, -1))\n",
    "        return jnp.concatenate([context, action], axis=1)\n",
    "\n",
    "    def get_ucb_actions(self, context, grid, args):\n",
    "        return jnp.array([self.get_upper_confidence_bound(self.get_state(context, a), *args) for a in grid])\n",
    "\n",
    "    def discrete_inference(self, context, args):\n",
    "        grid = self.action_anchors\n",
    "        ucb_all_actions = self.get_ucb_actions(context,grid,args) \n",
    "        idx = jnp.argmax(ucb_all_actions)\n",
    "        grid = jnp.array(grid)\n",
    "        return jnp.array([grid[idx]])\n",
    "\n",
    "    def update_data_pool(self, context, action, reward):\n",
    "        state = self.get_state(context, action)\n",
    "        self.past_states = jnp.concatenate([self.past_states, state])\n",
    "        self.rewards = jnp.concatenate([self.rewards, jnp.array([reward])])\n",
    "\n",
    "    def update_agent(self, context, action, reward):\n",
    "        state = self.get_state(context, action)\n",
    "        S, _ = self.get_story_data()\n",
    "        self.K_matrix_inverse = self.efficient_update_gram_matrix(S, state, self.K_matrix_inverse)\n",
    "        self.update_data_pool(context, action, reward)\n",
    "\n",
    "    def efficient_update_gram_matrix(self, S, state, K_matrix_inverse):\n",
    "        K_S_s = self.kernel.evaluate(S, state)\n",
    "        K_ss = self.kernel.evaluate(state, state)\n",
    "        s = K_ss + self.reg_lambda - jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, K_S_s))\n",
    "        Z_12 = - 1/s * (jnp.dot(K_matrix_inverse, K_S_s))\n",
    "        Z_21 =  - 1/s * (jnp.dot(K_S_s.T, K_matrix_inverse))\n",
    "        Z_11 = K_matrix_inverse + s * jnp.dot(Z_12, Z_21)\n",
    "        K_matrix_inverse = jnp.block([[Z_11, Z_12], [Z_21, 1/s]])\n",
    "        return K_matrix_inverse\n",
    "    \n",
    "class BatchKernelUCB:\n",
    "\n",
    "    def __init__(self, settings, kernel):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self.rng = np.random.RandomState(123)\n",
    "        self.reg_lambda = settings['reg_lambda']\n",
    "        self.kernel = kernel\n",
    "        self.settings = settings\n",
    "        self.name = 'Batch-KUCB'\n",
    "\n",
    "    def get_story_data(self):\n",
    "        return self.past_states, self.past_rewards\n",
    "\n",
    "    def set_gram_matrix(self):\n",
    "        K = self.kernel.gram_matrix(self.past_states)\n",
    "        K += self.reg_lambda * jnp.eye(K.shape[0])\n",
    "        self.K_matrix_inverse = jnp.linalg.inv(K)\n",
    "        \n",
    "    def instantiate(self, env):\n",
    "        self.action_anchors = env.get_anchor_points()\n",
    "        actions, contexts, rewards = env.get_logging_data()\n",
    "        states = self.get_states(contexts, actions)\n",
    "        self.past_states = jnp.array(states)\n",
    "        self.past_rewards = jnp.expand_dims(jnp.array(rewards), axis=1)\n",
    "        self.set_gram_matrix()\n",
    "        \n",
    "    def set_beta(self):\n",
    "        self.beta_t = 0.1\n",
    "\n",
    "    def get_upper_confidence_bound(self, states, K_matrix_inverse, S, past_rewards):\n",
    "        K_S_s = self.kernel.evaluate(S, states)\n",
    "        mean = jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, past_rewards))\n",
    "        K_ss = self.kernel.evaluate(states, states)\n",
    "        std = np.diag((1/self.reg_lambda)*(K_ss - jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, K_S_s))))\n",
    "        ucb = jnp.squeeze(mean) + self.beta_t * jnp.sqrt(std)\n",
    "        return ucb\n",
    "\n",
    "    def sample_actions(self, contexts):\n",
    "        self.set_beta()\n",
    "        S, rewards = self.get_story_data()\n",
    "        args = self.K_matrix_inverse, S, rewards\n",
    "        return self.continuous_inference(contexts, args)\n",
    "\n",
    "    def continuous_inference(self, contexts, args):\n",
    "        nb_gradient_steps = 0\n",
    "        if nb_gradient_steps == 0:\n",
    "            return self.discrete_inference(contexts, args)\n",
    "        else:\n",
    "            def func(action):\n",
    "                state = self.get_state(contexts, action)\n",
    "                return self.get_upper_confidence_bound(state, *args)\n",
    "\n",
    "            a0 = self.discrete_inference(contexts, args)\n",
    "            max_hessian_eigenvalue = jnp.max(jsp.linalg.eigh(hessian(func)(a0), eigvals_only=True))\n",
    "            step_size = jnp.nan_to_num(1 / max_hessian_eigenvalue)\n",
    "            a_t = a0\n",
    "            for _ in range(nb_gradient_steps):\n",
    "                gradient = jnp.nan_to_num(grad(func)(a_t))\n",
    "                a_t -= step_size * gradient\n",
    "            return a_t\n",
    "\n",
    "    def get_states(self, contexts, actions):\n",
    "        batch_size = contexts.shape[0]\n",
    "        contexts, actions = contexts.reshape((batch_size, -1)), actions.reshape((batch_size, 1))\n",
    "        return jnp.concatenate([contexts, actions], axis=1)\n",
    "\n",
    "    def get_ucb_actions(self, contexts, grid, args):\n",
    "        return jnp.transpose(jnp.array([self.get_upper_confidence_bound(self.get_states(contexts, a*np.ones((contexts.shape[0]))), *args) for a in grid]))\n",
    "\n",
    "    def discrete_inference(self, contexts, args):\n",
    "        grid = self.action_anchors\n",
    "        ucb_all_actions = self.get_ucb_actions(contexts, grid, args) \n",
    "        idx = jnp.argmax(ucb_all_actions, axis=1)\n",
    "        grid = jnp.array(grid)\n",
    "        return jnp.array([grid[idx]])\n",
    "\n",
    "    def update_data_pool(self, contexts, actions, rewards):\n",
    "        states = self.get_states(contexts, actions)\n",
    "        rewards = np.expand_dims(rewards, axis=1)\n",
    "        self.past_states = jnp.concatenate([self.past_states, states])\n",
    "        self.past_rewards = jnp.concatenate([self.past_rewards, rewards])\n",
    "\n",
    "    def update_agent(self, contexts, actions, rewards):\n",
    "        self.update_data_pool(contexts, actions, rewards)\n",
    "        self.set_gram_matrix()\n",
    "\n",
    "class SBPE:\n",
    "\n",
    "    def __init__(self, settings, kernel):\n",
    "        \"\"\"Initializes the class\n",
    "\n",
    "        Attributes:\n",
    "            random_seed (int):  random seed for data generation process\n",
    "\n",
    "        \"\"\"\n",
    "        self.rng = np.random.RandomState(123)\n",
    "        self.reg_lambda = settings['reg_lambda']\n",
    "        self.kernel = kernel\n",
    "        self.settings = settings\n",
    "        self.name = 'SBPE'\n",
    "\n",
    "    def get_story_data(self):\n",
    "        return self.past_states, self.past_rewards\n",
    "\n",
    "    def set_gram_matrix(self):\n",
    "        K = self.kernel.gram_matrix(self.past_states)\n",
    "        K += self.reg_lambda * jnp.eye(K.shape[0])\n",
    "        self.K_matrix_inverse = jnp.linalg.inv(K)\n",
    "        \n",
    "    def instantiate(self, env):\n",
    "        self.action_anchors = env.get_anchor_points()\n",
    "        actions, contexts, rewards = env.get_logging_data()\n",
    "        states = self.get_states(contexts, actions)\n",
    "        self.past_states = jnp.array(states)\n",
    "        self.past_rewards = jnp.expand_dims(jnp.array(rewards), axis=1)\n",
    "        self.set_gram_matrix()\n",
    "        \n",
    "    def set_beta(self):\n",
    "        self.beta_t = 0.1\n",
    "\n",
    "    def pure_exploitations(self, states, K_matrix_inverse, S, past_rewards):\n",
    "        K_S_s = self.kernel.evaluate(S, states)\n",
    "        return jnp.squeeze(jnp.dot(K_S_s.T, jnp.dot(K_matrix_inverse, past_rewards)))\n",
    "\n",
    "    def sample_actions(self, contexts):\n",
    "        S, rewards = self.get_story_data()\n",
    "        args = self.K_matrix_inverse, S, rewards\n",
    "        return self.continuous_inference(contexts, args)\n",
    "\n",
    "    def continuous_inference(self, contexts, args):\n",
    "        nb_gradient_steps = 0\n",
    "        if nb_gradient_steps == 0:\n",
    "            return self.discrete_inference(contexts, args)\n",
    "        else:\n",
    "            def func(action):\n",
    "                state = self.get_state(contexts, action)\n",
    "                return self.get_upper_confidence_bound(state, *args)\n",
    "\n",
    "            a0 = self.discrete_inference(contexts, args)\n",
    "            max_hessian_eigenvalue = jnp.max(jsp.linalg.eigh(hessian(func)(a0), eigvals_only=True))\n",
    "            step_size = jnp.nan_to_num(1 / max_hessian_eigenvalue)\n",
    "            a_t = a0\n",
    "            for _ in range(nb_gradient_steps):\n",
    "                gradient = jnp.nan_to_num(grad(func)(a_t))\n",
    "                a_t -= step_size * gradient\n",
    "            return a_t\n",
    "\n",
    "    def get_states(self, contexts, actions):\n",
    "        batch_size = contexts.shape[0]\n",
    "        contexts, actions = contexts.reshape((batch_size, -1)), actions.reshape((batch_size, 1))\n",
    "        return jnp.concatenate([contexts, actions], axis=1)\n",
    "\n",
    "    def get_exploitations(self, contexts, grid, args):\n",
    "        return jnp.transpose(jnp.array([self.pure_exploitations(self.get_states(contexts, a*np.ones((contexts.shape[0]))), *args) for a in grid]))\n",
    "\n",
    "    def discrete_inference(self, contexts, args):\n",
    "        grid = self.action_anchors\n",
    "        exploitations_all_actions = self.get_exploitations(contexts, grid, args) \n",
    "        idx = jnp.argmax(exploitations_all_actions, axis=1)\n",
    "        grid = jnp.array(grid)\n",
    "        return jnp.array([grid[idx]])\n",
    "\n",
    "    def update_data_pool(self, contexts, actions, rewards):\n",
    "        states = self.get_states(contexts, actions)\n",
    "        rewards = np.expand_dims(rewards, axis=1)\n",
    "        self.past_states = jnp.concatenate([self.past_states, states])\n",
    "        self.past_rewards = jnp.concatenate([self.past_rewards, rewards])\n",
    "\n",
    "    def update_agent(self, contexts, actions, rewards):\n",
    "        self.update_data_pool(contexts, actions, rewards)\n",
    "        self.set_gram_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d11c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self, dataset, n_logging_samples):\n",
    "        self.dataset = dataset\n",
    "        self.n_logging_samples = n_logging_samples\n",
    "\n",
    "    def sample_data(self, n):\n",
    "        return self.dataset.sample_data(n_samples=n)\n",
    "\n",
    "    def sample_reward(self, actions, labels):\n",
    "        actions = np.squeeze(actions)\n",
    "        return - self.dataset.get_losses_from_actions(labels, actions)\n",
    "\n",
    "    def get_anchor_points(self):\n",
    "        return np.arange(-10, 10, 0.5)\n",
    "    \n",
    "    def get_logging_data(self):\n",
    "        actions, contexts, losses, _, _, _ = self.dataset.sample_logged_data(self.n_logging_samples)\n",
    "        return actions, contexts, -losses\n",
    "\n",
    "\n",
    "def instantiate_metrics():\n",
    "    return {\n",
    "        'time': [],\n",
    "        'average_loss': [],\n",
    "        'regret': [],\n",
    "        'cumulated_loss': [],\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'agent': 'k_ucb',\n",
    "    'T': T,\n",
    "    'random_seed': 42,\n",
    "    'reg_lambda': 1,\n",
    "    'expname': 'experiment_k_ucb'\n",
    "}\n",
    "\n",
    "n_logging_samples = 10\n",
    "M = 8\n",
    "\n",
    "def batch_bandit_experiment(random_seed, dataset_name, settings, agent):\n",
    "    \n",
    "    dataset = get_dataset_by_name(dataset_name, random_seed)\n",
    "\n",
    "    start_experiment(random_seed, dataset, agent.name)\n",
    "    \n",
    "    # Model setting\n",
    "    env = Environment(dataset, n_logging_samples)\n",
    "    kernel = Polynomial(settings)\n",
    "    agent.instantiate(env)\n",
    "    metrics = instantiate_metrics()\n",
    "    best_strategy_rewards = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    batch_size = n_logging_samples\n",
    "    for step in tqdm(range(M)):\n",
    "\n",
    "        # choose a random context.\n",
    "        batch_size *= 2\n",
    "        contexts, labels = env.sample_data(n=batch_size)\n",
    "        # iterate learning algorithm for 1 round.\n",
    "        actions = agent.sample_actions(contexts)\n",
    "        rewards = env.sample_reward(actions, labels)\n",
    "\n",
    "        agent.update_agent(contexts, actions, rewards)\n",
    "        # get best_strategy's reward for the current context.\n",
    "    #     best_strategy_rewards.append(env.get_best_reward_in_context(context, label))\n",
    "        t = time.time() - t0\n",
    "        metrics['time'].append(t)\n",
    "        average_reward = np.mean(agent.past_rewards[1:])\n",
    "        metrics['average_loss'].append(-average_reward)\n",
    "        metrics['cumulated_loss'].append(np.sum(metrics['average_loss']))\n",
    "        print('Average reward: {}'.format(average_reward))\n",
    "\n",
    "    batch_online_losses = np.array([-average_reward._value for average_reward in metrics['average_reward']])\n",
    "\n",
    "    return np.expand_dims(batch_online_losses, axis=0)\n",
    "\n",
    "\n",
    "agent = BatchKernelUCB(settings, kernel)\n",
    "batch_bandit_online_losses = []\n",
    "\n",
    "for random_seed in range(10):\n",
    "    batch_bandit_online_losses.append(batch_bandit_experiment(random_seed, dataset_name, settings, agent))\n",
    "\n",
    "batch_bandit_online_losses = np.concatenate(batch_bandit_online_losses, axis=0)\n",
    "batch_kucb_online_losses, batch_k_ucb_online_losses_std = np.mean(batch_bandit_online_losses, axis=0), np.std(batch_bandit_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f998c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'agent': 'k_ucb',\n",
    "    'T': T,\n",
    "    'random_seed': 42,\n",
    "    'reg_lambda': 1,\n",
    "    'expname': 'experiment_k_ucb'\n",
    "}\n",
    "M = 8\n",
    "\n",
    "kernel = Polynomial(settings)\n",
    "agent = SBPE(settings, kernel)\n",
    "batch_bandit_online_losses = []\n",
    "\n",
    "for random_seed in range(10):\n",
    "    batch_bandit_online_losses.append(batch_bandit_experiment(random_seed, dataset_name, settings, agent))\n",
    "\n",
    "batch_bandit_online_losses = np.concatenate(batch_bandit_online_losses)\n",
    "batch_sbpe_online_losses, batch_sbpe_online_losses_std = np.mean(batch_bandit_online_losses, axis=0), np.std(batch_bandit_online_losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642ab6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
