{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fa689b",
   "metadata": {},
   "source": [
    "# Sequential CRM Experiments\n",
    "\n",
    "- ref paper: https://arxiv.org/pdf/1502.02362.pdf\n",
    "- ref code & data: https://www.cs.cornell.edu/~adith/POEM/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c25f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3299e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8645d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jaxopt\n",
    "from jax.scipy.special import expit as jexpit\n",
    "from jax.scipy.optimize import minimize as jminimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad01a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da5c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf7812",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- //(softmax temperature ?)\n",
    "- make sure loss is good\n",
    "- fix pi0 to be bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c93204",
   "metadata": {},
   "source": [
    "---\n",
    "##Â Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbaa9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='scene'\n",
    "# dataset_name='yeast'\n",
    "#dataset_name='tmc2007'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4757a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 294)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_ = load_svmlight_file(dataset_name+'_train.svm', multilabel=True)\n",
    "X_train = np.array(X_train.todense())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c48b812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 294)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test_ = load_svmlight_file(dataset_name+'_test.svm', multilabel=True)\n",
    "X_test = np.array(X_test.todense())\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d7704b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labeller = MultiLabelBinarizer()\n",
    "y_train = onehot_labeller.fit_transform(y_train_).astype(int)\n",
    "y_test = onehot_labeller.transform(y_test_).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "10ebda13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1805, 294), (602, 294))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.vstack([X_train, X_test])\n",
    "y_all = np.vstack([y_train, y_test])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=.25, random_state=0\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "567d21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'tmc_2007':\n",
    "    print(\"reducing dimension for TMC dataset\")\n",
    "    fh = GaussianRandomProjection(n_components=1000)\n",
    "    X_train = fh.fit_transform(X_train)\n",
    "    X_test = fh.transform(X_test)\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15fdd9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = onehot_labeller.classes_.astype(int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7514c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1685.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         120.]),\n",
       " array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cf30b",
   "metadata": {},
   "source": [
    "FYI: Error rate of null policy (always predict 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "105dcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0963455149501662"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ab902",
   "metadata": {},
   "source": [
    "---\n",
    "## Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1279d1",
   "metadata": {},
   "source": [
    "### CRM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768c1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRMDataset(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.propensities_ = []\n",
    "        self.actions_ = []\n",
    "        self.rewards_ = []\n",
    "        self.features_ = []\n",
    "        \n",
    "        self.propensities_np = None\n",
    "        self.actions_np = None\n",
    "        self.rewards_np = None\n",
    "        self.features_np = None\n",
    "\n",
    "        self.check()\n",
    "        \n",
    "    def __str__(self):\n",
    "        if not self.propensities_np:\n",
    "            return '<CRMDataset>'\n",
    "        self._generate_numpys()\n",
    "        return '<CRMDataset propensities:%s actions:%s rewards:%s features:%s>' % (\n",
    "            self.propensities_np.shape,\n",
    "            self.actions_np.shape,\n",
    "            self.rewards_np.shape,\n",
    "            self.features_np.shape\n",
    "        )\n",
    "    \n",
    "    __repr__ = __str__\n",
    "        \n",
    "    def check(self):\n",
    "        assert len(self.features_) == len(self.propensities_) == len(self.rewards_) == len(self.actions_)\n",
    "        assert type(self.propensities_) == type(self.actions_) == type(self.rewards_) == type(self.features_) == list        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.propensities_)\n",
    "        \n",
    "    def _generate_arrays(self):\n",
    "        if self.propensities_np is not None and len(self.propensities_np) == len(self.propensities_):\n",
    "            return        \n",
    "        self.propensities_np = jnp.vstack(self.propensities_)\n",
    "        self.actions_np = jnp.vstack(self.actions_)\n",
    "        self.rewards_np = jnp.vstack(self.rewards_)\n",
    "        self.features_np = jnp.vstack(self.features_)\n",
    "        \n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.actions_np\n",
    "\n",
    "    @property\n",
    "    def propensities(self):\n",
    "        return self.propensities_np\n",
    "    \n",
    "    @property\n",
    "    def rewards(self):\n",
    "        return self.rewards_np\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.features_np\n",
    "        \n",
    "    def update_from_supervised_dataset(self, X, y, probas, n_samples=4, labels=labels):\n",
    "        # X is (n,d)\n",
    "        # y is (n,k)\n",
    "        # probas is (n,k)\n",
    "\n",
    "        assert len(X) == len(y) == len(probas), (len(X) , len(y) , len(probas))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            for k in range(n_samples):\n",
    "\n",
    "                chosen_actions = np.array([np.random.binomial(1, p=probas[i,j]) for j in labels])\n",
    "                self.actions_ += [chosen_actions]\n",
    "                self.propensities_ += [probas[i,:]]\n",
    "                self.features_ += [X[i,:]]\n",
    "                self.rewards_ += [sum(int(y[i,j] == chosen_actions[j]) for j in labels)]\n",
    "                \n",
    "        self._generate_arrays()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d83b97",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b870bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, beta):\n",
    "        self.d = beta.shape[0]\n",
    "        self.k = beta.shape[1]\n",
    "        self.beta_ = beta\n",
    "        \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return self.beta_\n",
    "    \n",
    "    @beta.setter\n",
    "    def beta(self, beta):\n",
    "        # beta is (d, k)\n",
    "        self.beta_ = beta.reshape(self.d, self.k)\n",
    "        \n",
    "    @staticmethod\n",
    "    def random_model(d, k, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        beta = jnp.array(np.random.normal(size=(d, k)))\n",
    "        return Model(beta)\n",
    "    \n",
    "    @staticmethod\n",
    "    def null_model(d, k):\n",
    "        beta = jnp.array(np.zeros((d, k)))\n",
    "        return Model(beta)\n",
    "\n",
    "    def predict(self, features):\n",
    "        wx = jnp.dot(features, self.beta_)\n",
    "        return (wx > 0).astype(int)\n",
    "    \n",
    "    def predict_proba(self, features, actions):\n",
    "        wx = jnp.dot(features, self.beta_)\n",
    "        actions_sign = 2 * actions - 1\n",
    "        return jexpit(actions_sign * wx)\n",
    "    \n",
    "    def expected_hamming_loss(self, X, y):\n",
    "        y_invert = 1 - y\n",
    "        invert_probas = self.predict_proba(X, y_invert)\n",
    "        return invert_probas.sum() / (self.k * y.shape[0])    \n",
    "        \n",
    "    def crm_loss(self, crm_dataset: CRMDataset, \n",
    "                 up_clip: float = 1000, \n",
    "                 low_clip: float = 1e-9,\n",
    "                 lambda_: float = 0):\n",
    "        n = crm_dataset.features.shape[0]\n",
    "\n",
    "        predictions = self.predict_proba(crm_dataset.features, crm_dataset.actions)\n",
    "        predictions = jnp.clip(predictions, 1e-9, None)        \n",
    "#         predictions[predictions == 0] = 1. # to avoid log(0)\n",
    "        instances_with_nonzero_proba = (predictions.sum(axis=1) > 0).astype(int)\n",
    "        \n",
    "        per_instance_log_predictions = jnp.log(predictions).sum(axis=1)\n",
    "        per_instance_log_propensities = jnp.log(crm_dataset.propensities).sum(axis=1)\n",
    "        per_instance_log_propensities = jnp.clip(per_instance_log_propensities, jnp.log(low_clip), None) #\n",
    "        per_instance_log_importance_weights = per_instance_log_predictions - per_instance_log_propensities\n",
    "#         per_instance_log_importance_weights = jnp.clip(per_instance_log_importance_weights, \n",
    "#                                                        jnp.log(low_clip), None)\n",
    "        \n",
    "        per_instance_importance_weights = jnp.exp(per_instance_log_importance_weights)                \n",
    "        per_instance_importance_weights = per_instance_importance_weights * instances_with_nonzero_proba\n",
    "        per_instance_importance_weights = jnp.clip(per_instance_importance_weights, 0, up_clip)\n",
    "        per_instance_importance_weights = per_instance_importance_weights.reshape(\n",
    "            (per_instance_importance_weights.shape[0], 1)\n",
    "        )\n",
    "        \n",
    "        per_instance_importance_weighted_rewards = jnp.multiply(\n",
    "            self.k - crm_dataset.rewards, # to make a loss\n",
    "            per_instance_importance_weights\n",
    "        )\n",
    "        \n",
    "        total_loss = per_instance_importance_weighted_rewards.sum() / per_instance_importance_weights.sum()\n",
    "        \n",
    "        if lambda_ > 0:\n",
    "            total_loss += lambda_ * jnp.sqrt(jnp.var(per_instance_importance_weights) / n)\n",
    "        \n",
    "        return total_loss / self.k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42854657",
   "metadata": {},
   "source": [
    "### CF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87d388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(model, X, y, sampling_probas, crm_dataset: CRMDataset, \n",
    "                  samples_per_instance:int = 4, verbose=False, **loss_args):\n",
    "        \n",
    "    # prior_crm_dataset will get extended\n",
    "    crm_dataset.update_from_supervised_dataset(\n",
    "        X, y, sampling_probas, \n",
    "        n_samples=samples_per_instance\n",
    "    )\n",
    "    if verbose: print(\"Dataset ready:\", len(crm_dataset), file=sys.stderr)\n",
    "    def _loss(beta):\n",
    "        model.beta = beta\n",
    "        return model.crm_loss(crm_dataset, **loss_args)\n",
    "        \n",
    "    optimizer = jaxopt.ScipyMinimize(method='L-BFGS-B', fun=_loss, maxiter=1000, tol=1e-9)\n",
    "    solution = optimizer.run(model.beta)\n",
    "    if verbose: print(\"Optimi finished:\", solution.state, file=sys.stderr)\n",
    "    model.beta = solution.params\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aef896",
   "metadata": {},
   "source": [
    "----\n",
    "##Â Baselines & Skylines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170d08d",
   "metadata": {},
   "source": [
    " ![Perf from CRM article](./basesky.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11f3e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_results = {\n",
    "    'scene': {\n",
    "        'pi0': 1.543, 'ips': 1.193, 'poem': 1.168, 'pi*':.659\n",
    "    },\n",
    "    'yeast': {\n",
    "        'pi0': 5.547, 'ips': 4.635, 'poem': 4.480, 'pi*':2.282\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "def stoch_hloss(pi, X_test, y_test):\n",
    "    predictions = pi.predict_proba(X_test)\n",
    "    predictions = np.array([_[:,1] for _ in predictions]).T\n",
    "    idx = np.where(y_test == 0)\n",
    "    fp = predictions[idx].sum()\n",
    "    idx = np.where(y_test == 1)\n",
    "    fn = (1-predictions[idx]).sum()\n",
    "    return (fn+fp)/(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "\n",
    "def result_table(pi0, pistar, X_test, y_test, ips_loss=None, poem_loss=None):\n",
    "    \n",
    "    stats = paper_results[dataset_name]\n",
    "    \n",
    "    print('Baseline -- paper: %.3f -- ours: %.3f' % (stats[\"pi0\"]/y_test.shape[1], \n",
    "                                                     stoch_hloss(pi0, X_test, y_test)))\n",
    "    print('IPS      -- paper: %.3f' % (stats[\"ips\"]/y_test.shape[1]), end='')\n",
    "    if ips_loss is not None:\n",
    "        print(' -- ours: %.3f' % ips_loss)\n",
    "    else:\n",
    "        print()\n",
    "    print('POEM     -- paper: %.3f' % (stats[\"poem\"]/y_test.shape[1]), end='')\n",
    "    if poem_loss is not None:\n",
    "        print(' -- ours: %.3f' % poem_loss)\n",
    "    else:\n",
    "        print()\n",
    "    print('Skyline  -- paper: %.3f -- ours: %.3f' % (stats[\"pi*\"]/y_test.shape[1], \n",
    "                                                     stoch_hloss(pistar, X_test, y_test)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d72a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegressionCV(max_iter=10000, n_jobs=6))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistar = MultiOutputClassifier(LogisticRegressionCV(max_iter=10000, n_jobs=6))\n",
    "pistar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4d3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6c55dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning pi0 on 90 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=KNeighborsClassifier(n_neighbors=30), n_jobs=6)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0 = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=30),#penalty='l2', C=1e-9, fit_intercept=0, intercept_scaling=0), \n",
    "                            n_jobs=6)\n",
    "\n",
    "X_0, _, y_0, _ = train_test_split(X_train, y_train, test_size=.95, random_state=0)\n",
    "print('learning pi0 on', len(X_0), 'data points')\n",
    "\n",
    "pi0.fit(X_0, y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8fe0ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi0 = MultiOutputClassifier(LogisticRegression(dual=True, solver='liblinear', max_iter=1000), n_jobs=6)\n",
    "# X_0, _, y_0, _ = train_test_split(X_train, y_train, test_size=.95, random_state=42)\n",
    "# pi0.fit(X_0, y_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd69647",
   "metadata": {},
   "source": [
    "---\n",
    "## Classical CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb76e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# useful to check the online CRM optimization\n",
    "# (this CRM dataset is supposedly less biased than the online one the optim observes)\n",
    "ref_crm_dataset = CRMDataset().update_from_supervised_dataset(\n",
    "    X_train, y_train, \n",
    "    np.ones((X_train.shape[0], y_train.shape[1]))*.5,\n",
    "    n_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5c27347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta0 Exp. H. loss: 0.532\n",
      "beta0 CRM Loss (unif): 0.539\n"
     ]
    }
   ],
   "source": [
    "random_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "print('beta0 Exp. H. loss: %.3f' % random_model.expected_hamming_loss(X_test, y_test))\n",
    "print('beta0 CRM Loss (unif): %.3f' % random_model.crm_loss(ref_crm_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f604e403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "POEM    E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n",
      "IPS     E[HL]: 0.300 | CRM Loss (++data): 0.289 | CRM Loss: 0.143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [158]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m ips_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [ips_model\u001b[38;5;241m.\u001b[39mexpected_hamming_loss(X_test, y_test)]    \n\u001b[1;32m     28\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43miterate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoem_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_probas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoem_crm_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples_per_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_clip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOEM    E[HL]: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | CRM Loss (++data): \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | CRM Loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     37\u001b[0m     poem_model\u001b[38;5;241m.\u001b[39mexpected_hamming_loss(X_test, y_test), \n\u001b[1;32m     38\u001b[0m     poem_model\u001b[38;5;241m.\u001b[39mcrm_loss(ref_crm_dataset), \n\u001b[1;32m     39\u001b[0m     poem_model\u001b[38;5;241m.\u001b[39mcrm_loss(poem_crm_dataset)\n\u001b[1;32m     40\u001b[0m ))\n\u001b[1;32m     41\u001b[0m poem_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [poem_model\u001b[38;5;241m.\u001b[39mexpected_hamming_loss(X_test, y_test)]    \n",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36miterate_model\u001b[0;34m(model, X, y, sampling_probas, crm_dataset, samples_per_instance, verbose, **loss_args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate_model\u001b[39m(model, X, y, sampling_probas, crm_dataset: CRMDataset, \n\u001b[1;32m      2\u001b[0m                   samples_per_instance:\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_args):\n\u001b[1;32m      3\u001b[0m         \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# prior_crm_dataset will get extended\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mcrm_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_from_supervised_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_probas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_per_instance\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset ready:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(crm_dataset), file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_loss\u001b[39m(beta):\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mCRMDataset.update_from_supervised_dataset\u001b[0;34m(self, X, y, probas, n_samples, labels)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [X[i,:]]\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mint\u001b[39m(y[i,j] \u001b[38;5;241m==\u001b[39m chosen_actions[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m labels)]\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mCRMDataset._generate_arrays\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropensities_np \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropensities_)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions_np \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions_)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards_np \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewards_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_np \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:1708\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype)\u001b[0m\n\u001b[1;32m   1706\u001b[0m   arrs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(atleast_2d)(tup)\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1708\u001b[0m   arrs \u001b[38;5;241m=\u001b[39m [atleast_2d(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tup]\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(arrs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:1708\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1706\u001b[0m   arrs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(atleast_2d)(tup)\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1708\u001b[0m   arrs \u001b[38;5;241m=\u001b[39m [atleast_2d(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tup]\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(arrs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ips_losses = []\n",
    "poem_losses = []\n",
    "for i in range(10):\n",
    "    ips_model = Model.null_model(X_test.shape[1], y_test.shape[1])\n",
    "#     ips_model = Model.random_model(X_test.shape[1], y_test.shape[1], seed=i*42)\n",
    "    poem_model = Model(ips_model.beta)\n",
    "    \n",
    "    ips_crm_dataset = CRMDataset()\n",
    "    poem_crm_dataset = CRMDataset()\n",
    "    sampling_probas = pi0.predict_proba(X_train)\n",
    "    sampling_probas = np.array([_[:,1] for _ in sampling_probas]).T\n",
    "    \n",
    "    np.random.seed(i*42)\n",
    "    iterate_model(\n",
    "        ips_model, X_train, y_train, sampling_probas, ips_crm_dataset, \n",
    "        samples_per_instance=4,\n",
    "        verbose=0, \n",
    "        lambda_ = 0,\n",
    "        up_clip = 1e3\n",
    "    )\n",
    "    print(\"IPS     E[HL]: %.3f | CRM Loss (++data): %.3f | CRM Loss: %.3f\" % (\n",
    "        ips_model.expected_hamming_loss(X_test, y_test), \n",
    "        ips_model.crm_loss(ref_crm_dataset), \n",
    "        ips_model.crm_loss(ips_crm_dataset)\n",
    "    ))\n",
    "    ips_losses += [ips_model.expected_hamming_loss(X_test, y_test)]    \n",
    "\n",
    "    np.random.seed(i*42)\n",
    "    iterate_model(\n",
    "        poem_model, X_train, y_train, sampling_probas, poem_crm_dataset, \n",
    "        samples_per_instance=4,\n",
    "        verbose=0, \n",
    "        lambda_ = .001, \n",
    "        up_clip = 1e3,\n",
    "    )\n",
    "    print(\"POEM    E[HL]: %.3f | CRM Loss (++data): %.3f | CRM Loss: %.3f\" % (\n",
    "        poem_model.expected_hamming_loss(X_test, y_test), \n",
    "        poem_model.crm_loss(ref_crm_dataset), \n",
    "        poem_model.crm_loss(poem_crm_dataset)\n",
    "    ))\n",
    "    poem_losses += [poem_model.expected_hamming_loss(X_test, y_test)]    \n",
    "print()\n",
    "\n",
    "ips_losses = np.array(ips_losses)\n",
    "poem_losses = np.array(poem_losses)\n",
    "\n",
    "diff = ips_losses - poem_losses\n",
    "\n",
    "print('CI(L(IPS) - L(POEM)) @ alpha=5%%: [%.4f ; %.4f]' % (\n",
    "    diff.mean() - 1.64*np.std(diff)/np.sqrt(10), diff.mean() + 1.64*np.std(diff)/np.sqrt(10)\n",
    "), '\\n')\n",
    "\n",
    "result_table(pi0, pistar, X_test, y_test, ips_loss=np.mean(ips_losses), poem_loss=np.mean(poem_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54520c99",
   "metadata": {},
   "source": [
    "---\n",
    "## Sequential CRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3232f46",
   "metadata": {},
   "source": [
    "### Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(object):\n",
    "    \n",
    "    def __init__(self, name, ref_crm_dataset, X_test, y_test):\n",
    "        self.name = name\n",
    "        self.ref_crm_dataset = ref_crm_dataset\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.hamming_loss = []\n",
    "        self.crm_loss = []\n",
    "        self.unif_crm_loss = []\n",
    "        self.betas = []\n",
    "        self.n_samples = []\n",
    "        self.n_actions = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def update(self, model: Model, crm_dataset: CRMDataset):\n",
    "        self.betas += [model.beta]\n",
    "        self.hamming_loss += [model.expected_hamming_loss(self.X_test, self.y_test)]\n",
    "        self.crm_loss += [model.crm_loss(crm_dataset)]\n",
    "        self.unif_crm_loss += [model.crm_loss(self.ref_crm_dataset)]\n",
    "        self.n_samples += [len(crm_dataset)]\n",
    "        self.n_actions += [np.sum(crm_dataset.actions_)]\n",
    "        self.rewards += [np.sum(crm_dataset.rewards_)]\n",
    "        \n",
    "    def show_last(self):\n",
    "        print(\n",
    "            '<', self.name,\n",
    "            'Ham. loss: %.5f' % self.hamming_loss[-1], \n",
    "            'CRM loss: %.5f' % self.crm_loss[-1],\n",
    "            'CRM loss (U): %.5f' % self.unif_crm_loss[-1],\n",
    "            '|beta|=%.2f' % np.sqrt((self.betas[-1]**2).sum()), \n",
    "            'n=%d' % self.n_samples[-1],\n",
    "            '|A|=%d' % self.n_actions[-1],\n",
    "            '|R|=%d' % self.rewards[-1],\n",
    "            '>',\n",
    "            file=sys.stderr\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae40cb",
   "metadata": {},
   "source": [
    "### The Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a56e01",
   "metadata": {},
   "source": [
    "rollouts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035c476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "static_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "dynamic_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "\n",
    "static_crm_dataset = CRMDataset()\n",
    "dynamic_crm_dataset = CRMDataset()\n",
    "\n",
    "static_loss_history = LossHistory(\"Static\", ref_crm_dataset, X_test, y_test)\n",
    "dynamic_loss_history = LossHistory(\"Dynamic\", ref_crm_dataset, X_test, y_test)\n",
    "\n",
    "epochs = 1\n",
    "n_episods = 1\n",
    "batch = int(len(X_train) / n_episods)\n",
    "replays = 4\n",
    "\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    print('*'*30, 'PASS %d/%d'% (_+1, epochs), '*'*30, file=sys.stderr)\n",
    "    for episod in range(n_episods):\n",
    "        start = episod*batch\n",
    "        end = (episod+1)*batch\n",
    "        t_start = time.time()\n",
    "\n",
    "        # current slice of dataset\n",
    "        X = X_train[start:end,:]\n",
    "        y = y_train[start:end,:]\n",
    "       \n",
    "        #### static CRM \n",
    "        ## action probas\n",
    "        sampling_probas_static = pi0.predict_proba(X)\n",
    "        sampling_probas_static = np.array([_[:,1] for _ in sampling_probas_static]).T\n",
    "        ## optimize\n",
    "        iterate_model(\n",
    "            static_model, X, y, sampling_probas_static, static_crm_dataset, \n",
    "            samples_per_instance=replays,\n",
    "        )\n",
    "        ## record\n",
    "        static_loss_history.update(static_model, static_crm_dataset)\n",
    "        static_loss_history.show_last()\n",
    "        \n",
    "        #### sequential CRM \n",
    "        ## action probas\n",
    "#         if episod == 0:\n",
    "#             sampling_probas_dynamic = sampling_probas_static\n",
    "#         else:\n",
    "#             sampling_probas_dynamic = dynamic_model.predict_proba(X, y)        \n",
    "#         ## optimize\n",
    "#         iterate_model(\n",
    "#             dynamic_model, X, y, sampling_probas_dynamic, dynamic_crm_dataset,\n",
    "#             samples_per_instance=replays,\n",
    "#         )\n",
    "#         ## record\n",
    "#         dynamic_loss_history.update(dynamic_model, dynamic_crm_dataset)\n",
    "#         dynamic_loss_history.show_last()\n",
    "        t_end = time.time()\n",
    "    \n",
    "        print('*'*20, 'episod: %d/%d' % (episod+1, n_episods), \n",
    "              'time: %ds' % (t_end - t_start), '*'*20, file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50197f",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ee6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "plt.title('Loss Evolution over Rollouts')\n",
    "ax.set_xlabel('Rollouts')\n",
    "ax.set_ylabel('CRM Loss')\n",
    "ax.plot(static_loss_history.crm_loss, '--', label='CRM loss (static)')\n",
    "# ax.plot(dynamic_loss_history.crm_loss, '--', label='CRM loss (dynamic)')\n",
    "ax.plot(static_loss_history.unif_crm_loss, '--', label='unif. CRM loss (static)')\n",
    "# ax.plot(dynamic_loss_history.unif_crm_loss, '--', label='unif. CRM loss (dynamic)')\n",
    "ax.legend(loc='upper right')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(static_loss_history.hamming_loss, label='Hamming loss (static)')\n",
    "# ax2.plot(dynamic_loss_history.hamming_loss, label='Hamming loss (dynamic)')\n",
    "ax2.set_ylabel('Hamming Loss')\n",
    "ax2.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Action')\n",
    "plt.plot(jexpit(static_model.beta.mean(axis=0)),'--', label='static')\n",
    "# plt.plot(jexpit(beta_dynamic.mean(axis=0)),'--', label='dynamic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d44929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Feature')\n",
    "plt.plot(jexpit(static_model.beta.mean(axis=1)),'--', label='static')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Sampling Probas per Action')\n",
    "plt.plot(sampling_probas_static.mean(axis=0),'--', label='static')\n",
    "# plt.plot(sampling_probas_dynamic.mean(axis=0),'--', label='dynamic')\n",
    "plt.plot(y_test.mean(axis=0), label='label average', alpha=.5)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
