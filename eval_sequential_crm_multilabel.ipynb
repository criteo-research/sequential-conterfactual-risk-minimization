{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c25f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3299e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import jax.numpy as np\n",
    "#import jaxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad01a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da5c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d5146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize as sp_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf7812",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- //(softmax temperature ?)\n",
    "- //feedback = nb de match entre predictions et labels (par ligne)\n",
    "- //model : fix feature map : phi(X,A)(i,j) = X[i,j]*sign(A[i,j])\n",
    "- (NTH) provide gradients to optim\n",
    "- make sure loss is good\n",
    "- fix pi0 to be bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c93204",
   "metadata": {},
   "source": [
    "---\n",
    "##Â Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbaa9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='scene'\n",
    "# dataset_name='yeast'\n",
    "#dataset_name='tmc2007'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4757a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 294)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_ = load_svmlight_file(dataset_name+'_train.svm', multilabel=True)\n",
    "X_train = np.array(X_train.todense())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c48b812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 294)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test_ = load_svmlight_file(dataset_name+'_test.svm', multilabel=True)\n",
    "X_test = np.array(X_test.todense())\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d656e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labeller = MultiLabelBinarizer()\n",
    "y_train = onehot_labeller.fit_transform(y_train_).astype(int)\n",
    "y_test = onehot_labeller.transform(y_test_).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65069b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1805, 294), (602, 294))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.vstack([X_train, X_test])\n",
    "y_all = np.vstack([y_train, y_test])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=.25, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab31ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'tmc_2007':\n",
    "    print(\"reducing dimension for TMC dataset\")\n",
    "    fh = GaussianRandomProjection(n_components=1000)\n",
    "    X_train = fh.fit_transform(X_train)\n",
    "    X_test = fh.transform(X_test)\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fdd9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = onehot_labeller.classes_.astype(int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7514c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.67e+03, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.34e+02,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 1.00e+00]),\n",
       " array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cf30b",
   "metadata": {},
   "source": [
    "FYI: Error rate of null policy (always predict 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105dcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.069767441860465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ab902",
   "metadata": {},
   "source": [
    "---\n",
    "## Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1279d1",
   "metadata": {},
   "source": [
    "### CRM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768c1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRMDataset(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.propensities_ = []\n",
    "        self.actions_ = []\n",
    "        self.rewards_ = []\n",
    "        self.features_ = []\n",
    "        \n",
    "        self.propensities_np = None\n",
    "        self.actions_np = None\n",
    "        self.rewards_np = None\n",
    "        self.features_np = None\n",
    "\n",
    "        self.check()\n",
    "        \n",
    "    def __str__(self):\n",
    "        if not self.propensities_np:\n",
    "            return '<CRMDataset>'\n",
    "        self._generate_numpys()\n",
    "        return '<CRMDataset propensities:%s actions:%s rewards:%s features:%s>' % (\n",
    "            self.propensities_np.shape,\n",
    "            self.actions_np.shape,\n",
    "            self.rewards_np.shape,\n",
    "            self.features_np.shape\n",
    "        )\n",
    "    \n",
    "    __repr__ = __str__\n",
    "        \n",
    "    def check(self):\n",
    "        assert len(self.features_) == len(self.propensities_) == len(self.rewards_) == len(self.actions_)\n",
    "        assert type(self.propensities_) == type(self.actions_) == type(self.rewards_) == type(self.features_) == list        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.propensities_)\n",
    "        \n",
    "    def _generate_numpys(self):\n",
    "        if self.propensities_np is not None and len(self.propensities_np) == len(self.propensities_):\n",
    "            return        \n",
    "        self.propensities_np = np.vstack(self.propensities_)\n",
    "        self.actions_np = np.vstack(self.actions_)\n",
    "        self.rewards_np = np.vstack(self.rewards_)\n",
    "        self.features_np = np.vstack(self.features_)\n",
    "        \n",
    "    @property\n",
    "    def actions(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.actions_np\n",
    "\n",
    "    @property\n",
    "    def propensities(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.propensities_np\n",
    "    \n",
    "    @property\n",
    "    def rewards(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.rewards_np\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "#         self._generate_numpys()\n",
    "        return self.features_np\n",
    "        \n",
    "    def update_from_supervised_dataset(self, X, y, probas, n_samples=4, labels=labels):\n",
    "        # X is (n,d)\n",
    "        # y is (n,k)\n",
    "        # probas is (n,k)\n",
    "\n",
    "        assert len(X) == len(y) == len(probas), (len(X) , len(y) , len(probas))\n",
    "\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            for k in range(n_samples):\n",
    "\n",
    "                chosen_actions = np.array([np.random.binomial(1, p=probas[i,j]) for j in labels])\n",
    "                self.actions_ += [chosen_actions]\n",
    "                self.propensities_ += [probas[i,:]]\n",
    "                self.features_ += [X[i,:]]\n",
    "                self.rewards_ += [sum(int(y[i,j] == chosen_actions[j]) for j in labels)]\n",
    "                \n",
    "        self._generate_numpys()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d83b97",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17f4fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, beta):\n",
    "        self.d = beta.shape[0]\n",
    "        self.k = beta.shape[1]\n",
    "        self.beta_ = beta\n",
    "        \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return self.beta_\n",
    "    \n",
    "    @beta.setter\n",
    "    def beta(self, beta):\n",
    "        # beta is (d, k)\n",
    "        self.beta_ = beta.reshape(self.d, self.k)\n",
    "        \n",
    "    @staticmethod\n",
    "    def random_model(d, k):\n",
    "        beta = np.random.normal(size=(d, k))\n",
    "        return Model(beta)\n",
    "    \n",
    "    @staticmethod\n",
    "    def null_model(d, k):\n",
    "        beta = np.zeros(size=(d, k))\n",
    "        return Model(beta)\n",
    "\n",
    "    def predict(self, features):\n",
    "        wx = np.dot(features, self.beta_)\n",
    "        return (wx > 0).astype(int)\n",
    "    \n",
    "    def predict_proba(self, features, actions):\n",
    "        wx = np.dot(features, self.beta_)\n",
    "        actions_sign = 2 * actions - 1\n",
    "        return expit(actions_sign * wx)\n",
    "    \n",
    "    def expected_hamming_loss(self, X, y):\n",
    "        y_invert = 1 - y\n",
    "        invert_probas = self.predict_proba(X, y_invert)\n",
    "        return invert_probas.sum() / (self.k * y.shape[0])    \n",
    "        \n",
    "    def crm_loss(self, crm_dataset: CRMDataset, clip: float = 1000, lambda_: float = 0):\n",
    "        n = crm_dataset.features.shape[0]\n",
    "\n",
    "        predictions = self.predict_proba(crm_dataset.features, crm_dataset.actions)\n",
    "        \n",
    "        predictions[predictions == 0] = 1. # to avoid log(0)\n",
    "        instances_with_nonzero_proba = (predictions.sum(axis=1) > 0).astype(int)\n",
    "        \n",
    "        per_instance_log_predictions = np.log(predictions).sum(axis=1)\n",
    "        per_instance_log_propensities = np.log(crm_dataset.propensities).sum(axis=1)\n",
    "        per_instance_log_propensities = np.clip(per_instance_log_propensities, -100, None) #\n",
    "        per_instance_log_importance_weights = per_instance_log_predictions - per_instance_log_propensities\n",
    "        \n",
    "        per_instance_importance_weights = np.exp(per_instance_log_importance_weights)\n",
    "        per_instance_importance_weights = per_instance_importance_weights * instances_with_nonzero_proba\n",
    "        per_instance_importance_weights = np.clip(per_instance_importance_weights, 0, clip)\n",
    "        \n",
    "        per_instance_importance_weighted_rewards = np.multiply(\n",
    "            - crm_dataset.rewards, \n",
    "            per_instance_importance_weights\n",
    "        )\n",
    "        \n",
    "        total_loss = per_instance_importance_weighted_rewards.mean() #sum() / per_instance_importance_weights.sum()\n",
    "        \n",
    "        return total_loss / self.k\n",
    "\n",
    "#         ips_weights = np.ones((n, self.k))\n",
    "#         non_zero_propensities = np.where(crm_dataset.propensities > 0)\n",
    "#         ips_weights[non_zero_propensities] = predictions[non_zero_propensities] / crm_dataset.propensities[non_zero_propensities]\n",
    "#         ips_weights = np.clip(ips_weights, 0, clip)\n",
    "\n",
    "#         per_instance_weights = ips_weights.sum(axis=1)\n",
    "#         ips_sum = per_instance_weights.sum()\n",
    "\n",
    "#         per_instance_weights /= ips_sum\n",
    "\n",
    "#         per_instance_loss = (self.d - crm_dataset.rewards).flatten()\n",
    "\n",
    "#         total_loss = np.dot(per_instance_loss, per_instance_weights)\n",
    "\n",
    "#         if lambda_ > 0:\n",
    "#             # POEM\n",
    "#             total_loss += lambda_ * np.std(ips_weights) / np.sqrt(n)\n",
    "\n",
    "#         return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42854657",
   "metadata": {},
   "source": [
    "### CF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87d388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(model, X, y, sampling_probas, crm_dataset: CRMDataset, \n",
    "                  samples_per_instance:int = 4, verbose=1):\n",
    "        \n",
    "    # prior_crm_dataset will get extended\n",
    "    crm_dataset.update_from_supervised_dataset(\n",
    "        X, y, sampling_probas, \n",
    "        n_samples=samples_per_instance\n",
    "    )\n",
    "    if verbose:\n",
    "        print('CRM dataset:', len(crm_dataset), end=' ', file=sys.stderr)\n",
    "        \n",
    "    def _loss(beta):\n",
    "        model.beta = beta\n",
    "        return model.crm_loss(crm_dataset)\n",
    "        \n",
    "    solution = sp_minimize(_loss, model.beta, method='L-BFGS-B')\n",
    "\n",
    "    model.beta = solution.x\n",
    "    \n",
    "    if verbose:\n",
    "        print(solution.nit, 'steps -> %.3f' % solution.fun, file=sys.stderr)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aef896",
   "metadata": {},
   "source": [
    "----\n",
    "##Â Baselines & Skylines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170d08d",
   "metadata": {},
   "source": [
    " ![Perf from CRM article](./basesky.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd49157",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_results = {\n",
    "    'scene': {\n",
    "        'pi0': 1.543, 'ips': 1.193, 'poem': 1.168, 'pi*':.659\n",
    "    },\n",
    "    'yeast': {\n",
    "        'pi0': 5.547, 'ips': 4.635, 'poem': 4.480, 'pi*':2.282\n",
    "\n",
    "    }\n",
    "}\n",
    "def result_table(model: Model, pi0, pistar):\n",
    "    stats = paper_results[dataset_name]\n",
    "    \n",
    "#     def hloss(pi, X_test, y_test):\n",
    "#         pi0_predictions = pi.predict_proba(X_test)\n",
    "#         pi0_predictions = np.array([_[:,1] for _ in pi0_predictions]).T\n",
    "#         idx = np.where(y_test == 0)\n",
    "#         fp = pi0_predictions[idx].sum()\n",
    "\n",
    "#         idx = np.where(y_test == 1)\n",
    "#         fn = (1-pi0_predictions[idx]).sum()\n",
    "\n",
    "#         return (fn+fp)/(y_test.shape[0]*y_test.shape[1])\n",
    "    \n",
    "#     print('Baseline -- paper: %.3f -- ours (stoch): %.3f' % (stats[\"pi0\"]/y_test.shape[1], \n",
    "#                                                      hloss(pi0, y_test, pi0.predict(X_test))))\n",
    "    print('Baseline -- paper: %.3f -- ours (det): %.3f' % (stats[\"pi0\"]/y_test.shape[1], \n",
    "                                                     hamming_loss(y_test, pi0.predict(X_test))))\n",
    "    print('IPS      -- paper: %.3f -- ours: %.3f' % (stats[\"ips\"]/y_test.shape[1], \n",
    "                                                     model.expected_hamming_loss(X_test, y_test)))\n",
    "    print('POEM     -- paper: %.3f' % (stats[\"poem\"]/y_test.shape[1]))\n",
    "    print('Skyline  -- paper: %.3f -- ours: %.3f' % (stats[\"pi*\"]/y_test.shape[1], \n",
    "                                                     hamming_loss(y_test, pistar.predict(X_test))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1edca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegressionCV(max_iter=10000, n_jobs=6))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistar = MultiOutputClassifier(LogisticRegressionCV(max_iter=10000, n_jobs=6))\n",
    "pistar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947af472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning pi0 on 90 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(), n_jobs=6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0 = MultiOutputClassifier(LogisticRegression(),#penalty='l2', C=1e-9, fit_intercept=0, intercept_scaling=0), \n",
    "                            n_jobs=6)\n",
    "\n",
    "X_0, _, y_0, _ = train_test_split(X_train, y_train, test_size=.95, random_state=0)\n",
    "print('learning pi0 on', len(X_0), 'data points')\n",
    "\n",
    "pi0.fit(X_0, y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f21cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = []\n",
    "# # for _ in range(10):\n",
    "#     X_all = np.vstack([X_train, X_test])\n",
    "#     y_all = np.vstack([y_train, y_test])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X_all, y_all, test_size=.25\n",
    "#     )\n",
    "#     pi0 = MultiOutputClassifier(LogisticRegressionCV(max_iter=10000, n_jobs=6))\n",
    "# #     pi0 = MultiOutputClassifier(LogisticRegression(),n_jobs=6)\n",
    "# #     X_0, _, y_0, _ = train_test_split(X_train, y_train, test_size=.95, random_state=0)\n",
    "#     pi0.fit(X_train, y_train)\n",
    "#     l += [hamming_loss(y_test, pi0.predict(X_test))]\n",
    "# np.mean(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd69647",
   "metadata": {},
   "source": [
    "---\n",
    "## Sequential CRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387033a",
   "metadata": {},
   "source": [
    "### Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c399eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(object):\n",
    "    \n",
    "    def __init__(self, name, ref_crm_dataset, X_test, y_test):\n",
    "        self.name = name\n",
    "        self.ref_crm_dataset = ref_crm_dataset\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.hamming_loss = []\n",
    "        self.crm_loss = []\n",
    "        self.unif_crm_loss = []\n",
    "        self.betas = []\n",
    "        self.n_samples = []\n",
    "        self.n_actions = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def update(self, model: Model, crm_dataset: CRMDataset):\n",
    "        self.betas += [model.beta]\n",
    "        self.hamming_loss += [model.expected_hamming_loss(self.X_test, self.y_test)]\n",
    "        self.crm_loss += [model.crm_loss(crm_dataset)]\n",
    "        self.unif_crm_loss += [model.crm_loss(self.ref_crm_dataset)]\n",
    "        self.n_samples += [len(crm_dataset)]\n",
    "        self.n_actions += [np.sum(crm_dataset.actions_)]\n",
    "        self.rewards += [np.sum(crm_dataset.rewards_)]\n",
    "        \n",
    "    def show_last(self):\n",
    "        print(\n",
    "            '<', self.name,\n",
    "            'Ham. loss: %.5f' % self.hamming_loss[-1], \n",
    "            'CRM loss: %.5f' % self.crm_loss[-1],\n",
    "            'CRM loss (U): %.5f' % self.unif_crm_loss[-1],\n",
    "            '|beta|=%.2f' % np.sqrt((self.betas[-1]**2).sum()), \n",
    "            'n=%d' % self.n_samples[-1],\n",
    "            '|A|=%d' % self.n_actions[-1],\n",
    "            '|R|=%d' % self.rewards[-1],\n",
    "            '>',\n",
    "            file=sys.stderr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1e4caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_crm_dataset = CRMDataset().update_from_supervised_dataset(\n",
    "    X_train, y_train, \n",
    "    np.ones((X_train.shape[0], y_train.shape[1]))*.5,\n",
    "    n_samples=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51001a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta0 Exp. H. loss: 0.365\n",
      "beta0 CRM Loss (unif): -0.507\n"
     ]
    }
   ],
   "source": [
    "random_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "print('beta0 Exp. H. loss: %.3f' % random_model.expected_hamming_loss(X_test, y_test))\n",
    "print('beta0 CRM Loss (unif): %.3f' % random_model.crm_loss(ref_crm_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f794a410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3787375415282392"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test, random_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32c8dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6550029277618499"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_model.expected_hamming_loss(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e44a0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6531007751937985"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test, static_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c04cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef7940c",
   "metadata": {},
   "source": [
    "### The Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035c476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "****************************** PASS 1/1 ******************************\n",
      "******************** episod: 1/10 time: 0s ********************\n",
      "CRM dataset: 180 5 steps -> -770.524\n",
      "< Static Ham. loss: 0.34345 CRM loss: -770.52389 CRM loss (U): -0.49520 |beta|=41.71 n=180 |A|=172 |R|=899 >\n",
      "******************** episod: 2/10 time: 20s ********************\n",
      "CRM dataset: 360 6 steps -> -814.574\n",
      "< Static Ham. loss: 0.29611 CRM loss: -814.57441 CRM loss (U): -0.49867 |beta|=41.62 n=360 |A|=358 |R|=1811 >\n",
      "******************** episod: 3/10 time: 23s ********************\n",
      "CRM dataset: 540 6 steps -> -815.174\n",
      "< Static Ham. loss: 0.31394 CRM loss: -815.17400 CRM loss (U): -0.49615 |beta|=41.47 n=540 |A|=557 |R|=2701 >\n",
      "******************** episod: 4/10 time: 38s ********************\n",
      "CRM dataset: 720 7 steps -> -818.709\n",
      "< Static Ham. loss: 0.28620 CRM loss: -818.70878 CRM loss (U): -0.49501 |beta|=41.18 n=720 |A|=740 |R|=3589 >\n",
      "******************** episod: 5/10 time: 44s ********************\n",
      "CRM dataset: 900 "
     ]
    }
   ],
   "source": [
    "static_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "dynamic_model = Model.random_model(X_test.shape[1], y_test.shape[1])\n",
    "\n",
    "static_crm_dataset = CRMDataset()\n",
    "dynamic_crm_dataset = CRMDataset()\n",
    "\n",
    "static_loss_history = LossHistory(\"Static\", ref_crm_dataset, X_test, y_test)\n",
    "dynamic_loss_history = LossHistory(\"Dynamic\", ref_crm_dataset, X_test, y_test)\n",
    "\n",
    "epochs = 1\n",
    "n_episods = 10\n",
    "batch = int(len(X_train) / n_episods)\n",
    "replays = 1\n",
    "\n",
    "t_end = t_start = time.time()\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    print('*'*30, 'PASS %d/%d'% (_+1, epochs), '*'*30, file=sys.stderr)\n",
    "    for episod in range(n_episods):\n",
    "        \n",
    "        t_end = time.time()\n",
    "        start = episod*batch\n",
    "        end = (episod+1)*batch\n",
    "        print('*'*20, 'episod: %d/%d' % (episod+1, n_episods), \n",
    "              'time: %ds' % (t_end - t_start), '*'*20, file=sys.stderr)\n",
    "        t_start = time.time()\n",
    "\n",
    "        # current slice of dataset\n",
    "        X = X_train[start:end,:]\n",
    "        y = y_train[start:end,:]\n",
    "       \n",
    "        #### static CRM \n",
    "        ## action probas\n",
    "        sampling_probas_static = pi0.predict_proba(X)\n",
    "        sampling_probas_static = np.array([_[:,1] for _ in sampling_probas_static]).T\n",
    "        ## optimize\n",
    "        iterate_model(\n",
    "            static_model, X, y, sampling_probas_static, static_crm_dataset, \n",
    "            samples_per_instance=replays,\n",
    "        )\n",
    "        ## record\n",
    "        static_loss_history.update(static_model, static_crm_dataset)\n",
    "        static_loss_history.show_last()\n",
    "        \n",
    "        #### sequential CRM \n",
    "        ## action probas\n",
    "#         if episod == 0:\n",
    "#             sampling_probas_dynamic = sampling_probas_static\n",
    "#         else:\n",
    "#             sampling_probas_dynamic = dynamic_model.predict_proba(X, y)        \n",
    "#         ## optimize\n",
    "#         iterate_model(\n",
    "#             dynamic_model, X, y, sampling_probas_dynamic, dynamic_crm_dataset,\n",
    "#             samples_per_instance=replays,\n",
    "#         )\n",
    "#         ## record\n",
    "#         dynamic_loss_history.update(dynamic_model, dynamic_crm_dataset)\n",
    "#         dynamic_loss_history.show_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e76566",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table(static_model, pi0, pistar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf133b0",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ee6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "plt.title('Loss Evolution over Rollouts')\n",
    "ax.set_xlabel('Rollouts')\n",
    "ax.set_ylabel('CRM Loss')\n",
    "ax.plot(static_loss_history.crm_loss, '--', label='CRM loss (static)')\n",
    "ax.plot(dynamic_loss_history.crm_loss, '--', label='CRM loss (dynamic)')\n",
    "ax.plot(static_loss_history.unif_crm_loss, '--', label='unif. CRM loss (static)')\n",
    "ax.plot(dynamic_loss_history.unif_crm_loss, '--', label='unif. CRM loss (dynamic)')\n",
    "ax.legend(loc='upper right')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(static_loss_history.hamming_loss, label='Hamming loss (static)')\n",
    "ax2.plot(dynamic_loss_history.hamming_loss, label='Hamming loss (dynamic)')\n",
    "ax2.set_ylabel('Hamming Loss')\n",
    "ax2.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Action')\n",
    "plt.plot(expit(beta_static.mean(axis=0)),'--', label='static')\n",
    "plt.plot(expit(beta_dynamic.mean(axis=0)),'--', label='dynamic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d44929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Avg Proba per Feature')\n",
    "plt.plot(expit(beta_static.mean(axis=1)),'--', label='static')\n",
    "plt.plot(expit(beta_dynamic.mean(axis=1)),'--', label='dynamic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Sampling Probas per Action')\n",
    "plt.plot(sampling_probas_static.mean(axis=0),'--', label='static')\n",
    "plt.plot(sampling_probas_dynamic.mean(axis=0),'--', label='dynamic')\n",
    "plt.plot(y_test.mean(axis=0), label='label average', alpha=.5)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
